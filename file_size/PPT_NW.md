## ğŸ“¦ğŸ”§ 1. Importing Required Libraries


```python
import os                      # ğŸ“ For interacting with the operating system (file paths, directory checks, etc.)
import zipfile                 # ğŸ—œï¸ For handling ZIP archive files
import numpy as np             # ğŸ”¢ For numerical operations and arrays
import pandas as pd            # ğŸ¼ For data manipulation and analysis
from pathlib import Path       # ğŸ›¤ï¸ For object-oriented file path handling
from datetime import time      # â° For working with time objects (e.g., filtering by hour)
from functools import reduce   # ğŸ”„ For function-based reduction (e.g., combining multiple DataFrames)
from pandas import Timestamp   # ğŸ“… For handling timestamps specifically in pandas

from pptx.util import Inches                   # ğŸ“ For specifying size/dimensions of shapes or images in inches
from pptx import Presentation                  # ğŸ“Š For creating and editing PowerPoint presentations
from pptx.util import Pt                       # ğŸ”  For setting font size in points
from pptx.enum.shapes import MSO_SHAPE_TYPE    # ğŸ§© For identifying and handling different shape types in slides
from pptx.dml.color import RGBColor            # ğŸ¨ For setting custom RGB colors for text/shapes
from pptx.enum.text import PP_ALIGN            # ğŸ“ For setting paragraph alignment (left, center, right, etc.)
from pptx.chart.data import CategoryChartData  # ğŸ“ˆ For providing data to category charts (like bar/column charts)
```

## 2. âœ… `standard_cg_mapping`: Reusable Cell Group Standardization Dictionary


```python
# ğŸ”„ Master CG normalization dictionary (Reusable for all tech layers)
standard_cg_mapping = {
    # ğŸ§© South Region â€“ June 25 SZ (South Phase-3)
    'L9_South_June25_SZ'    : 'L9_South_June25_SZ',
    'L9_South_Jun25_SZ'     : 'L9_South_June25_SZ',
    'L9_South_Jun25_L9_SZ'  : 'L9_South_June25_SZ',
    'L9_South_Jun25_L18_SZ' : 'L9_South_June25_SZ',
    'L9_South_Jun25_L21_SZ' : 'L9_South_June25_SZ',

    # ğŸ§© South â€“ Dera Allah Yar (South Phase-3)
    'L9_South_June25_DeraAllAHYAR'    : 'L9_South_June25_DeraAllAHYAR',
    'L9_South_Jun25_DeraAllAHYAR'     : 'L9_South_June25_DeraAllAHYAR',
    'L9_South_Jun25_L9_DeraAllAHYAR'  : 'L9_South_June25_DeraAllAHYAR',
    'L9_South_Jun25_L18_DeraAllAHYAR' : 'L9_South_June25_DeraAllAHYAR',
    'L9_South_Jun25_L21_DeraAllAHYAR' : 'L9_South_June25_DeraAllAHYAR',
    
    
    # ğŸ™ï¸ Jacobabad (South- Phase-2)
    'L9_Jacobabad_Apr25_2G'  : 'L9_Jacobabad_Apr25_2G',
    'L9_Jacobabad_Apr25_3G'  : 'L9_Jacobabad_Apr25_2G',
    'L9_Jacobabad_Apr25_ALL' : 'L9_Jacobabad_Apr25_2G',
    'L9_Jacobabad_Apr25_L9'  : 'L9_Jacobabad_Apr25_2G',
    'L9_Jacobabad_Apr25_L18' : 'L9_Jacobabad_Apr25_2G',
    'L9_Jacobabad_Apr25_L21' : 'L9_Jacobabad_Apr25_2G',

    # ğŸ™ï¸ Shikarpur (South- Phase-2)
    'L9_Control_Shikarpur_2G'  : 'L9_Control_Shikarpur_2G',
    'L9_Control_Shikarpur_3G'  : 'L9_Control_Shikarpur_2G',
    'L9_Control_Shikarpur_L18' : 'L9_Control_Shikarpur_2G',

    # ğŸï¸ Khuzdar (South- Phase-2)
    'L9_Khuzdar_SZ_2G'  : 'L9_Khuzdar_SZ_2G',
    'L9_Khuzdar_SZ_3G'  : 'L9_Khuzdar_SZ_2G',
    'L9_khuzdar_SZ'     : 'L9_Khuzdar_SZ_2G',
    'L9_khuzdar_L9_SZ'  : 'L9_Khuzdar_SZ_2G',
    'L9_khuzdar_L18_SZ' : 'L9_Khuzdar_SZ_2G',
    'L9_khuzdar_L21_SZ' : 'L9_Khuzdar_SZ_2G',

    # ğŸ™ï¸ Major Cities â€“ Balochistan (South- Phase-2)
    'L9_Control_MajCitiesBaluchistan_2G'     : 'L9_Control_MajCitiesBaluchistan_2G',
    'L9_Control_MajCitiesBaluchistan_3G'     : 'L9_Control_MajCitiesBaluchistan_2G',
    'L9_Control_MajCitiesBaluchistan_L18&21' : 'L9_Control_MajCitiesBaluchistan_2G',
    'L9_Control_MajCitiesBaluchistan_L18'    : 'L9_Control_MajCitiesBaluchistan_2G',
    'L9_Control_MajCitiesBaluchistan_L21'    : 'L9_Control_MajCitiesBaluchistan_2G',
    
    # âš“ HUB (South- Phase-2)
    'L9_Hub_Apr25_2G_SZ'	:	'L9_Hub_Apr25_2G_SZ',
    'L9_Hub_Apr25_3G_SZ'	:	'L9_Hub_Apr25_2G_SZ',
    'L9_Hub_Apr25_ALL_SZ'	:	'L9_Hub_Apr25_2G_SZ',
    'L9_Hub_Apr25_L9_SZ'	:	'L9_Hub_Apr25_2G_SZ',
    'L9_Hub_Apr25_L18_SZ'	:	'L9_Hub_Apr25_2G_SZ',
    'L9_Hub_Apr25_L21_SZ'	:	'L9_Hub_Apr25_2G_SZ',
    
    
    # âš“ HUB Control (South- Phase-2)
    'HUB_Control_2G' : 'HUB_Control_2G',
    'HUB_Control_3G' : 'HUB_Control_2G',
    'HUB_Control_4G' : 'HUB_Control_2G',
    
    # ğŸŒ´ Turbat SZ (South- Phase-2)
    'L9_Turbat_Apr25_2G_SZ'  : 'L9_Turbat_Apr25_2G_SZ',
    'L9_Turbat_Apr25_3G_SZ'  : 'L9_Turbat_Apr25_2G_SZ',
    'L9_Turbat_Apr25_ALL_SZ' : 'L9_Turbat_Apr25_2G_SZ',
    'L9_Turbat_Apr25_L9_SZ'  : 'L9_Turbat_Apr25_2G_SZ',
    'L9_Turbat_Apr25_L18_SZ' : 'L9_Turbat_Apr25_2G_SZ',
    'L9_Turbat_Apr25_L21_SZ' : 'L9_Turbat_Apr25_2G_SZ',

    # âš“ Gwadar (South- Phase-2)
    'L2100_Gwadar_2G_City'             : 'L2100_Gwadar_2G_City',
    'L2100_Gwadar_City_3G_U2100+u900'  : 'L2100_Gwadar_2G_City',
    'L2100_Gwadar_City_4G_L1800+L2100' : 'L2100_Gwadar_2G_City',
    'GWADAR_CONTROL_L1800'             : 'L2100_Gwadar_2G_City',
    'GWADAR_CONTROL_L2100'             : 'L2100_Gwadar_2G_City',

    # ğŸ§­ North Sunset â€“ (North Phase-3)
    
    '2G_Sunset_NORTH_B2_SZ'		:	'2G_Sunset_NORTH_B2_SZ',
    '3G_Sunset_NORTH_B2_SZ'		:	'2G_Sunset_NORTH_B2_SZ',
    '4G_Sunset_NORTH_B2_SZ'		: 	'2G_Sunset_NORTH_B2_SZ',
    'L900_Sunset_NORTH_B2_SZ'	:	'2G_Sunset_NORTH_B2_SZ',
    'L1800_Sunset_NORTH_B2_SZ'	:	'2G_Sunset_NORTH_B2_SZ',
    'L2100_Sunset_NORTH_B2_SZ'	:	'2G_Sunset_NORTH_B2_SZ',

    # ğŸ§­ Kohat (North Phase-3)
    '2G_Sunset_N_KOHAT_SZ'		:	'2G_Sunset_N_KOHAT_SZ',
    '3G_Sunset_N_KOHAT_SZ'		:	'2G_Sunset_N_KOHAT_SZ',
    '4G_Sunset_N_KOHAT_SZ'		:	'2G_Sunset_N_KOHAT_SZ',
    'L900_Sunset_N_KOHAT_SZ'	:	'2G_Sunset_N_KOHAT_SZ',
    'L1800_Sunset_N_KOHAT_SZ'	:	'2G_Sunset_N_KOHAT_SZ',
    'L2100_Sunset_N_KOHAT_SZ'	:	'2G_Sunset_N_KOHAT_SZ',

    # ğŸ§­ Hangu (North Phase-3)
    '2G_Sunset_N_HANGU_SZ'		:	'2G_Sunset_N_HANGU_SZ',
    '3G_Sunset_N_HANGU_SZ'		:	'2G_Sunset_N_HANGU_SZ',
    '4G_Sunset_N_HANGU_SZ'		:	'2G_Sunset_N_HANGU_SZ',
    'L900_Sunset_N_HANGU_SZ'	:	'2G_Sunset_N_HANGU_SZ',
    'L1800_Sunset_N_HANGU_SZ'	:	'2G_Sunset_N_HANGU_SZ',
    'L2100_Sunset_N_HANGU_SZ'	:	'2G_Sunset_N_HANGU_SZ',

    # ğŸ§­ Bannu (North Phase-3)
    '2G_Sunset_N_BANNU_SZ'		:	'2G_Sunset_N_BANNU_SZ',
    '3G_Sunset_N_BANNU_SZ'		:	'2G_Sunset_N_BANNU_SZ',
    '4G_Sunset_N_BANNU_SZ'		:	'2G_Sunset_N_BANNU_SZ',
    'L900_Sunset_N_BANNU_SZ'	:	'2G_Sunset_N_BANNU_SZ',
    'L1800_Sunset_N_BANNU_SZ'	:	'2G_Sunset_N_BANNU_SZ',
    'L2100_Sunset_N_BANNU_SZ'	:	'2G_Sunset_N_BANNU_SZ',


    
    #ğŸ§© Center Region â€“ June 25 SZ (Center Phase-3)

    'GSM_BZ_Center_Region_Phase-03'				        :		'GSM_BZ_Center_Region_Phase-03',
    'UMTS_BZ_Center_Region_Phase-03'			        :		'GSM_BZ_Center_Region_Phase-03',
    'LTE_BZ_Center_Region_Phase-03'				        :		'GSM_BZ_Center_Region_Phase-03',
    'LTE_BZ_Center_Region_Phase-03_PTML-PTML-L-1800'	:		'GSM_BZ_Center_Region_Phase-03',
	
	#ğŸ§© Cluster-120 â€“ June 25 SZ (Center Phase-3)
    'GSM_Dep_Cluster_120'					:		'GSM_Dep_Cluster_120',
    'UMTS_Dep_Cluster_120'					:		'GSM_Dep_Cluster_120',
    'LTE_Dep_Cluster_120'					:		'GSM_Dep_Cluster_120',
    'LTE_Dep_Cluster_120_PTML-L-900'		:		'GSM_Dep_Cluster_120',
    'LTE_Dep_Cluster_120_PTML-L-1800'		:		'GSM_Dep_Cluster_120',
	
	#ğŸ§© Cluster-121 â€“ June 25 SZ (Center Phase-3)
    'GSM_Dep_Cluster_121'					:		'GSM_Dep_Cluster_121',
    'UMTS_Dep_Cluster_121'					:		'GSM_Dep_Cluster_121',
    'LTE_Dep_Cluster_121'					:		'GSM_Dep_Cluster_121',
    'LTE_Dep_Cluster_121_PTML-L-900'		:		'GSM_Dep_Cluster_121',
    'LTE_Dep_Cluster_121_PTML-L-1800'		:		'GSM_Dep_Cluster_121',
    'LTE_Dep_Cluster_121_PTML-L-2100'		:		'GSM_Dep_Cluster_121',
	
	#ğŸ§© Cluster-80 â€“ June 25 SZ (Center Phase-3)
    'GSM_Dep_Cluster_80'					:		'GSM_Dep_Cluster_80',
    'UMTS_Dep_Cluster_80'					:		'GSM_Dep_Cluster_80',
    'LTE_Dep_Cluster_80'					:		'GSM_Dep_Cluster_80',
    'LTE_Dep_Cluster_80_PTML-L-900'			:		'GSM_Dep_Cluster_80',
    'LTE_Dep_Cluster_80_PTML-L-1800'		:		'GSM_Dep_Cluster_80',

    #ğŸ§© Cluster-15 â€“ June 25 SZ (Center Phase-3)
    'GSM_Dep_No_BZ_Cluster_15'				:		'GSM_Dep_No_BZ_Cluster_15',
    'UMTS_Dep_No_BZ_Cluster_15'				:		'GSM_Dep_No_BZ_Cluster_15',
    'LTE_Dep_No_BZ_Cluster_15'				:		'GSM_Dep_No_BZ_Cluster_15',
    'LTE_Dep_No_BZ_Cluster_15_PTML-L-900'	:		'GSM_Dep_No_BZ_Cluster_15',
    'LTE_Dep_No_BZ_Cluster_15_PTML-L-1800'	:		'GSM_Dep_No_BZ_Cluster_15',
    'LTE_Dep_No_BZ_Cluster_15_PTML-L-2100'	:		'GSM_Dep_No_BZ_Cluster_15',
	
	
	#ğŸ§© Cluster-19 â€“ June 25 SZ (Center Phase-3)
    'GSM_Dep_No_BZ_Cluster_19'				:		'GSM_Dep_No_BZ_Cluster_19',
    'UMTS_Dep_No_BZ_Cluster_19'				:		'GSM_Dep_No_BZ_Cluster_19',
    'LTE_Dep_No_BZ_Cluster_19'				:		'GSM_Dep_No_BZ_Cluster_19',
    'LTE_Dep_No_BZ_Cluster_19_PTML-L-900'	:		'GSM_Dep_No_BZ_Cluster_19',
    'LTE_Dep_No_BZ_Cluster_19_PTML-L-1800'	:		'GSM_Dep_No_BZ_Cluster_19',
	
 
    #ğŸ§© Cluster-33 â€“ June 25 SZ (Center Phase-3)
    'GSM_Dep_No_BZ_Cluster_33'				:		'GSM_Dep_No_BZ_Cluster_33',
    'UMTS_Dep_No_BZ_Cluster_33'				:		'GSM_Dep_No_BZ_Cluster_33',
    'LTE_Dep_No_BZ_Cluster_33'				:		'GSM_Dep_No_BZ_Cluster_33',
    'LTE_Dep_No_BZ_Cluster_33_PTML-L-900'	:		'GSM_Dep_No_BZ_Cluster_33',
    'LTE_Dep_No_BZ_Cluster_33_PTML-L-1800'	:		'GSM_Dep_No_BZ_Cluster_33',
    'LTE_Dep_No_BZ_Cluster_33_PTML-L-2100'	:		'GSM_Dep_No_BZ_Cluster_33',
	
	#ğŸ§© Cluster-41 â€“ June 25 SZ (Center Phase-3)
    'GSM_Dep_No_BZ_Cluster_41'				:		'GSM_Dep_No_BZ_Cluster_41',
    'UMTS_Dep_No_BZ_Cluster_41'				:		'GSM_Dep_No_BZ_Cluster_41',
    'LTE_Dep_No_BZ_Cluster_41'				:		'GSM_Dep_No_BZ_Cluster_41',
    'LTE_Dep_No_BZ_Cluster_41_PTML-L-900'	:		'GSM_Dep_No_BZ_Cluster_41',
    'LTE_Dep_No_BZ_Cluster_41_PTML-L-1800'	:		'GSM_Dep_No_BZ_Cluster_41',
    'LTE_Dep_No_BZ_Cluster_41_PTML-L-2100'	:		'GSM_Dep_No_BZ_Cluster_41',

    #ğŸ§© Cluster-50 â€“ June 25 SZ (Center Phase-3)
    'GSM_Dep_No_BZ_Cluster_50'				:		'GSM_Dep_No_BZ_Cluster_50',
    'UMTS_Dep_No_BZ_Cluster_50'				:		'GSM_Dep_No_BZ_Cluster_50',
    'LTE_Dep_No_BZ_Cluster_50'				:		'GSM_Dep_No_BZ_Cluster_50',
    'LTE_Dep_No_BZ_Cluster_50_PTML-L-900'	:		'GSM_Dep_No_BZ_Cluster_50',
    'LTE_Dep_No_BZ_Cluster_50_PTML-L-1800'	:		'GSM_Dep_No_BZ_Cluster_50',
    'LTE_Dep_No_BZ_Cluster_50_PTML-L-2100'	:		'GSM_Dep_No_BZ_Cluster_50',
	
	
	#ğŸ§© Cluster-54 â€“ June 25 SZ (Center Phase-3)
    'GSM_Dep_No_BZ_Cluster_54'				:		'GSM_Dep_No_BZ_Cluster_54',
    'UMTS_Dep_No_BZ_Cluster_54'				:		'GSM_Dep_No_BZ_Cluster_54',
    'LTE_Dep_No_BZ_Cluster_54'				:		'GSM_Dep_No_BZ_Cluster_54',
    'LTE_Dep_No_BZ_Cluster_54_PTML-L-900'	:		'GSM_Dep_No_BZ_Cluster_54',
    'LTE_Dep_No_BZ_Cluster_54_PTML-L-1800'	:		'GSM_Dep_No_BZ_Cluster_54',
	

    #ğŸ§© Cluster-64 â€“ June 25 SZ (Center Phase-3)
    'GSM_Dep_No_BZ_Cluster_64'				:		'GSM_Dep_No_BZ_Cluster_64',
    'UMTS_Dep_No_BZ_Cluster_64'				:		'GSM_Dep_No_BZ_Cluster_64',
    'LTE_Dep_No_BZ_Cluster_64'				:		'GSM_Dep_No_BZ_Cluster_64',
    'LTE_Dep_No_BZ_Cluster_64_PTML-L-900'	:		'GSM_Dep_No_BZ_Cluster_64',
    'LTE_Dep_No_BZ_Cluster_64_PTML-L-1800'	:		'GSM_Dep_No_BZ_Cluster_64',
	
	
	#ğŸ§© SZ & BZ (Center Phase-3)
    'GSM_SZ_BZ_Center_Region_Phase-03'			        :		'GSM_SZ_BZ_Center_Region_Phase-03',
    'UMTS_SZ_BZ_Center_Region_Phase-03'			        :		'GSM_SZ_BZ_Center_Region_Phase-03',
    'LTE_SZ_BZ_Center_Region_Phase-03'			        :		'GSM_SZ_BZ_Center_Region_Phase-03',
    'LTE_SZ_BZ_Center_Region_Phase-03_PTML-PTML-L-900'	:		'GSM_SZ_BZ_Center_Region_Phase-03',
    'LTE_SZ_BZ_Center_Region_Phase-03_PTML-PTML-L-1800'	:		'GSM_SZ_BZ_Center_Region_Phase-03',
    'LTE_SZ_BZ_Center_Region_Phase-03_PTML-PTML-L-2100'	:		'GSM_SZ_BZ_Center_Region_Phase-03',
    	
    	
    #ğŸ§© SZ (Center Phase-3)	
    'GSM_SZ_Center_Region_Phase-03'				        :		'GSM_SZ_Center_Region_Phase_03',
    'UMTS_SZ_Center_Region_Phase-03'			        :		'GSM_SZ_Center_Region_Phase_03',
    'LTE_SZ_Center_Region_Phase-03'				        :		'GSM_SZ_Center_Region_Phase_03',
    'LTE_SZ_Center_Region_Phase-03_PTML-PTML-L-900'		:		'GSM_SZ_Center_Region_Phase_03',
    'LTE_SZ_Center_Region_Phase-03_PTML-PTML-L-1800'	:		'GSM_SZ_Center_Region_Phase_03',
    'LTE_SZ_Center_Region_Phase-03_PTML-PTML-L-2100'	:		'GSM_SZ_Center_Region_Phase_03',

    
    #ğŸ§© cluster_9 (Center Phase-4)	
    'GSM_SZ_Dep_Cluster_9'			    :		'SZ_Dep_Cluster_9',
    'UMTS_SZ_Dep_Cluster_9'			    :		'SZ_Dep_Cluster_9',
    'LTE_SZ_Dep_Cluster_9'			    :		'SZ_Dep_Cluster_9',
    'LTE_SZ_Dep_Cluster_9_PTML-L-1800'	:		'SZ_Dep_Cluster_9',
    'LTE_SZ_Dep_Cluster_9_PTML-L-2100'	:		'SZ_Dep_Cluster_9',
    'LTE_SZ_Dep_Cluster_9_PTML-L-900'	:		'SZ_Dep_Cluster_9',

    #ğŸ§© SAMBRIAL (Center Phase-4)	
    'GSM_Sunset_SAMBRIAL'			    :		'Sunset_SAMBRIAL',
    'UMTS_Sunset_SAMBRIAL'			    :		'Sunset_SAMBRIAL',
    'LTE_Sunset_SAMBRIAL'			    :		'Sunset_SAMBRIAL',
    'LTE_Sunset_SAMBRIAL_PTML-L-1800'	:		'Sunset_SAMBRIAL',
    'LTE_Sunset_SAMBRIAL_PTML-L-2100'	:		'Sunset_SAMBRIAL',
    'LTE_Sunset_SAMBRIAL_PTML-L-900'	:		'Sunset_SAMBRIAL',

    #ğŸ§© SIALKOT (Center Phase-4)
    'GSM_Sunset_SIALKOT'			    :		'Sunset_SIALKOT',
    'UMTS_Sunset_SIALKOT'			    :		'Sunset_SIALKOT',
    'LTE_Sunset_SIALKOT'			    :		'Sunset_SIALKOT',
    'LTE_Sunset_SIALKOT_PTML-L-1800'	:		'Sunset_SIALKOT',
    'LTE_Sunset_SIALKOT_PTML-L-2100'	:		'Sunset_SIALKOT',
    'LTE_Sunset_SIALKOT_PTML-L-900'		:		'Sunset_SIALKOT',
    
    #ğŸ§© PESHAWAR (North Phase-4)
    '2G_SUNSET_N_PESHAWAR_SZ'		    :		'Sunset_N_PESHAWAR_SZ',
    '3G_SUNSET_N_PESHAWAR_SZ'		    :		'Sunset_N_PESHAWAR_SZ',
    '4G_SUNSET_N_PESHAWAR_SZ'		    :		'Sunset_N_PESHAWAR_SZ',
    'L900_SUNSET_N_PESHAWAR_SZ'		    :		'Sunset_N_PESHAWAR_SZ',
    'L1800_SUNSET_N_PESHAWAR_SZ'		:		'Sunset_N_PESHAWAR_SZ',
    'L2100_SUNSET_N_PESHAWAR_SZ'		:		'Sunset_N_PESHAWAR_SZ',

    #ğŸ§© North (North Phase-4)
    '2G_SUNSET_NORTH_B3_SZ'			:		'Sunset_NORTH_B3_SZ',
    '3G_SUNSET_NORTH_B3_SZ'			:		'Sunset_NORTH_B3_SZ',
    '4G_SUNSET_NORTH_B3_SZ'			:		'Sunset_NORTH_B3_SZ',
    'L900_SUNSET_NORTH_B3_SZ'		:		'Sunset_NORTH_B3_SZ',
    'L1800_SUNSET_NORTH_B3_SZ'		:		'Sunset_NORTH_B3_SZ',
    'L2100_SUNSET_NORTH_B3_SZ'		:		'Sunset_NORTH_B3_SZ',
    
    # South SZ (South Phase-4)
    'L9_South_July25_2G_LKN_city_SZ'	:       'South_July25_2G_P4_SZ',
    'L9_South_July25_3G_LKN_city_SZ'	:       'South_July25_2G_P4_SZ',
    'L9_South_July25_4G_LKN_city_SZ'	:       'South_July25_2G_P4_SZ',
    'L9_South_July25_LKN_city_L9_SZ'	:       'South_July25_2G_P4_SZ',
    'L9_South_July25_LKN_city_L18_SZ'	:       'South_July25_2G_P4_SZ',
    'L9_South_July25_LKN_city_L21'	    :       'South_July25_2G_P4_SZ',
	
	# South Lardkana City (South Phase-4)
    'L9_South_July25_2G_Lark_city_SZ'	:  'South_July25_2G_Lark_city',
    'L9_South_July25_3G_Lark_city_SZ'	:  'South_July25_2G_Lark_city',
    'L9_South_July25_4G_Lark_city_SZ'	:  'South_July25_2G_Lark_city',
    'L9_South_July25_LARK_city_L9'	    :  'South_July25_2G_Lark_city',
    'L9_South_July25_LARK_city_L18'	    :  'South_July25_2G_Lark_city',
    'L9_South_July25_LARK_city_L21'	    :  'South_July25_2G_Lark_city',

    # Center Buffer Zone (Phase-5)
    'GSM_BZ_Center_Phase V'				    :	'BZ_Center_Phase V',
    'UMTS_BZ_Center_Phase-V'			    :	'BZ_Center_Phase V',
    'LTE_BZ_Center_Phase-V'				    :	'BZ_Center_Phase V',
    'LTE_BZ_Center_Phase-V_PTML-L-1800'		:	'BZ_Center_Phase V',
    'LTE_BZ_Center_Phase-V_PTML-L-2100'		:	'BZ_Center_Phase V',

    # Center Buffer Zone (Phase-6)
    'GSM_BZ_Center_Phase VI'			    :	'BZ_Center_Phase VI',
    'UMTS_BZ_Center_Phase-VI'			    :	'BZ_Center_Phase VI',
    'LTE_BZ_Center_Phase-VI'			    :	'BZ_Center_Phase VI',
    'LTE_BZ_Center_Phase-VI_PTML-L-1800'	:	'BZ_Center_Phase VI',
    'LTE_BZ_Center_Phase-VI_PTML-L-2100'	:	'BZ_Center_Phase VI',

    # Center Service+Buffer Zone (Phase-5)
    'GSM_SZ_BZ_Center_Phase V'			    :	'SZ_BZ_Center_Phase V',
    'UMTS_SZ_BZ_Center_Phase-V'			    :	'SZ_BZ_Center_Phase V',
    'LTE_SZ_BZ_Cente_Phase-V'			    :	'SZ_BZ_Center_Phase V',
    'LTE_SZ_BZ_Cente_Phase-V_PTML-L-1800'	:	'SZ_BZ_Center_Phase V',
    'LTE_SZ_BZ_Cente_Phase-V_PTML-L-2100'	:	'SZ_BZ_Center_Phase V',

    # Center Service+Buffer Zone (Phase-6)
    'GSM_SZ_BZ_Center_Phase VI'			        :	'SZ_BZ_Center_Phase VI',
    'UMTS_SZ_BZ_Center_Phase-VI'			    :	'SZ_BZ_Center_Phase VI',
    'LTE_SZ_BZ_Cente_Phase-VI'			        :	'SZ_BZ_Center_Phase VI',
    'LTE_SZ_BZ_Cente_Phase-VI_PTML-L-1800'		:	'SZ_BZ_Center_Phase VI',
    'LTE_SZ_BZ_Cente_Phase-VI_PTML-L-2100'		:	'SZ_BZ_Center_Phase VI',
    
    # Center Service Zonre (Phase-5) 
    'GSM_SZ_Center_Phase V'				    :	'SZ_Center_Phase V',
    'UMTS_SZ_Center_Phase-V'			    :	'SZ_Center_Phase V',
    'LTE_SZ_Center_Phase-V'				    :	'SZ_Center_Phase V',
    'LTE_SZ_Center_Phase-V_PTML-L-1800'		:	'SZ_Center_Phase V',
    'LTE_SZ_Center_Phase-V_PTML-L-2100'		:	'SZ_Center_Phase V',
    
    # Center Service Zonre (Phase-6)
    'GSM_SZ_Center_Phase VI'			       :	'SZ_Center_Phase VI',
    'UMTS_SZ_Center_Phase-VI'			       :	'SZ_Center_Phase VI',
    'LTE_SZ_Center_Phase-VI'			       :	'SZ_Center_Phase VI',
    'LTE_SZ_Center_Phase-VI_PTML-L-1800'	   :	'SZ_Center_Phase VI',
    'LTE_SZ_Center_Phase-VI_PTML-L-2100'	   :	'SZ_Center_Phase VI',

    # Chanab_Nagar_City (Phase-5)
    'GSM_Sunset_Chanab_Nagar_City'			    :	'Chanab_Nagar_City',
    'UMTS_Sunset_Chanab_Nagar_City'			    :	'Chanab_Nagar_City',
    'LTE_Sunset_Chanab_Nagar_City'			    :	'Chanab_Nagar_City',
    'LTE_Sunset_Chanab_Nagar_City_PTML-L-1800'	:	'Chanab_Nagar_City',
    'LTE_Sunset_Chanab_Nagar_City_PTML-L-2100'	:	'Chanab_Nagar_City',

    # DG_Khan_City (Phase-5)
    'GSM_Sunset_DG_KHAN_City'			    :	'DG_KHAN_City',
    'UMTS_Sunset_DG_KHAN_City'			    :	'DG_KHAN_City',
    'LTE_Sunset_DG_KHAN_City'			    :	'DG_KHAN_City',
    'LTE_Sunset_DG_KHAN_City_PTML-L-1800'	:	'DG_KHAN_City',
    'LTE_Sunset_DG_KHAN_City_PTML-L-2100'	:	'DG_KHAN_City',

    # DI_Khan_City (Phase-6)
    'GSM_Sunset_DI_KHAN_City'			    :	'DI_KHAN_City',
    'UMTS_Sunset_DI_KHAN_City'			    :	'DI_KHAN_City',
    'LTE_Sunset_DI_KHAN_City'			    :	'DI_KHAN_City',
    'LTE_Sunset_DI_KHAN_City_PTML-L-1800'	:	'DI_KHAN_City',	
    'LTE_Sunset_DI_KHAN_City_PTML-L-2100'	:	'DI_KHAN_City',

    # Fazilpur_City (Phase-5)
    'GSM_Sunset_Fazilpur_City'			    :	'Fazilpur_City',
    'UMTS_Sunset_Fazilpur_City'			    :	'Fazilpur_City',	
    'LTE_Sunset_Fazilpur_City'			    :	'Fazilpur_City',
    'LTE_Sunset_Fazilpur_City_PTML-L-1800'	:	'Fazilpur_City',
    'LTE_Sunset_Fazilpur_City_PTML-L-2100'	:	'Fazilpur_City',

    # JAMPUR_City (Phase-5)
    'GSM_Sunset_JAMPUR_City'			    :	'JAMPUR_City',
    'UMTS_Sunset_JAMPUR_City'			    :	'JAMPUR_City',
    'LTE_Sunset_JAMPUR_City'			    :	'JAMPUR_City',
    'LTE_Sunset_JAMPUR_City_PTML-L-1800'	:	'JAMPUR_City',
    'LTE_Sunset_JAMPUR_City_PTML-L-2100'	:	'JAMPUR_City',

    # MAMU_KANJAN_City (Phase-5)
    'GSM_Sunset_MAMU_KANJAN_City'			    :	'MAMU_KANJAN_City',
    'UMTS_Sunset_MAMU_KANJAN_City'			    :	'MAMU_KANJAN_City',
    'LTE_Sunset_MAMU_KANJAN_City'			    :	'MAMU_KANJAN_City',
    'LTE_Sunset_MAMU_KANJAN_City_PTML-L-1800'	:	'MAMU_KANJAN_City',
    'LTE_Sunset_MAMU_KANJAN_City_PTML-L-2100'	:    'MAMU_KANJAN_City',

    # RAJANPUR_City (Phase-5)
    'GSM_Sunset_RAJANPUR_City'			       :	'RAJANPUR_City',
    'UMTS_Sunset_RAJANPUR_City'			       :	'RAJANPUR_City',
    'LTE_Sunset_RAJANPUR_City'			       :	'RAJANPUR_City',
    'LTE_Sunset_RAJANPUR_City_PTML-L-1800'	   :	'RAJANPUR_City',
    'LTE_Sunset_RAJANPUR_City_PTML-L-2100'	   :	'RAJANPUR_City',
 
    # South Service Zone (Phase-5)
    'L9_South_July25_2G_22nd Batch_SZ'		:	'South_July25_22nd Batch_SZ',
    'L9_South_July25_3G_22nd Batch_SZ'		:	'South_July25_22nd Batch_SZ',
    'L9_South_July25_4G_22nd Batch_SZ'		:	'South_July25_22nd Batch_SZ',
    'L9_South_July25_22nd Batch_L9_SZ'		:	'South_July25_22nd Batch_SZ',
    'L9_South_July25_22nd Batch_L18_SZ'		:	'South_July25_22nd Batch_SZ',
    'L9_South_July25_22nd Batch_L21_SZ'		:	'South_July25_22nd Batch_SZ',

    # Shahdadkot (Phase-5)
    'L9_South_July25_2G_Shahdadkot_city_SZ'		:	'South_July25_Shahdadkot_city_SZ',
    'L9_South_July25_3G_Shahdadkot_city_SZ'		:	'South_July25_Shahdadkot_city_SZ',
    'L9_South_July25_4G_Shahdadkot_city_SZ'		:	'South_July25_Shahdadkot_city_SZ',
    'L9_South_July25_Shahdadkot_city_L9_SZ'		:	'South_July25_Shahdadkot_city_SZ',
    'L9_South_July25_Shahdadkot_city_L18_SZ'	:	'South_July25_Shahdadkot_city_SZ',	
    'L9_South_July25_Shahdadkot_city_L21_SZ'	:	'South_July25_Shahdadkot_city_SZ',

    # Shikarpur (Phase-5)
    'L9_South_July25_2G_Shikarpur_city_SZ'		:	'South_July25_Shikarpur_city_SZ',
    'L9_South_July25_3G_Shikarpur_city_SZ'		:	'South_July25_Shikarpur_city_SZ',
    'L9_South_July25_4G_Shikarpur_city_SZ'		:	'South_July25_Shikarpur_city_SZ',
    'L9_South_July25_Shikarpur_city_L9_SZ'		:	'South_July25_Shikarpur_city_SZ',
    'L9_South_July25_Shikarpur_city_L18_SZ'		:	'South_July25_Shikarpur_city_SZ',
    'L9_South_July25_Shikarpur_city_L21_SZ'		:	'South_July25_Shikarpur_city_SZ',
}
```

## ğŸ“‚ğŸ—œï¸ 3. Load & Extract Data from ZIP Files


```python
def load_gsm_from_zip_folder(zip_folder, keyword, required_columns, dtype=None):
    """
    ğŸ—œï¸ Extracts and combines CSV files from ZIPs in a folder, filtered by keyword and required columns.

    Parameters:
        zip_folder (str or Path): ğŸ“ Folder containing ZIP files.
        keyword (str): ğŸ” Keyword to filter relevant CSV filenames (e.g., "(GSM_Cell_Hourly)").
        required_columns (list): ğŸ§± List of required columns to read from CSVs.
        dtype (dict): Optional ğŸ§¬ dictionary specifying data types for specific columns.

    Returns:
        pd.DataFrame: ğŸ¼ Combined DataFrame with valid rows, or None if no match found.
    """
    zip_files = list(Path(zip_folder).glob("*.zip"))  # ğŸ“¦ List all ZIP files in the folder
    dfs = []  # ğŸ“‹ Initialize list to collect DataFrames

    for zip_file in zip_files:
        with zipfile.ZipFile(zip_file, 'r') as z:
            # ğŸ¯ Filter CSV files inside the ZIP that match the keyword
            csv_files = [f for f in z.namelist() if keyword in f and f.endswith(".csv")]

            for csv_file in csv_files:
                with z.open(csv_file) as f:
                    try:
                        df = pd.read_csv(
                            f,
                            usecols=required_columns,      # ğŸ§© Only load required columns
                            dtype=dtype,                   # ğŸ§¬ Apply custom dtypes if given
                            parse_dates=["Date"],          # ğŸ“† Ensure 'Date' is parsed as datetime
                            skiprows=range(6),             # ğŸª„ Skip first 6 header rows (formatting)
                            skipfooter=1,                  # ğŸš« Skip footer line if present
                            engine='python',               # ğŸ Use Python engine for flexibility
                            na_values=['NIL', '/0']        # â“ Replace invalid entries with NaN
                        )
                        dfs.append(df)  # âœ… Add valid DataFrame to the list
                    except ValueError:
                        # âš ï¸ Handle files missing required columns gracefully
                        print(f"Skipping {csv_file} in {zip_file.name} - Missing required columns.")

    if dfs:
        return pd.concat(dfs, ignore_index=True)  # ğŸ§© Combine all valid DataFrames
    else:
        print("No matching CSV files found or required columns missing. âŒ")
        return None
```

## ğŸ“ŠğŸ“¥ 4. Load & Clean LTE Hourly Dataset


```python
# ğŸ“ Define path and parameters for LTE CG Hourly data
zip_folder = "D:/Advance_Data_Sets/PPT_Sunset_NW"
keyword_lte = "(LTE_CG_DA)"
required_columns_lte = [
    'Date', 'LTE Cell Group', 'Data Volume (GB)', 
    'L.Traffic.User.VoIP.Avg', 'DL User Thrp (Mbps)',
    'DL User Thrp (Mbps)_NUM', 'DL User Thrp (Mbps)_DEN'
]

# ğŸ“¦ Load LTE data from ZIP files and rename key columns for standardization
lte_df = load_gsm_from_zip_folder(zip_folder, keyword_lte, required_columns_lte).\
    rename(columns={
        "LTE Cell Group": "LTE_Cell_Group",                            # ğŸ” Rename for consistency
        "Data Volume (GB)": "4G Data Traffic (GB)",                    # ğŸ“¦ 4G total traffic
        "L.Traffic.User.VoIP.Avg": "VoLTE Traffic (Erl)",              # ğŸ“ VoLTE traffic
        "DL User Thrp (Mbps)": "4G Overall Throughput (Mbps)"         # ğŸš€ Downlink throughput
    })

# ğŸ§© Apply standardized Cell Group (CG) names to LTE data for consistency across regions
lte_df['CG'] = lte_df['LTE_Cell_Group'].replace(standard_cg_mapping)
```

## ğŸ“¡ğŸ“¶ 5. Load & Preprocess LTE L900 Layer Data


```python
# ğŸ“¦ Load LTE L900 data from ZIP files and rename columns for clarity
keyword_lte_l900 = "(LTE_CG_DA_L900)"
lte_l900_df = load_gsm_from_zip_folder(zip_folder, keyword_lte_l900, required_columns_lte).\
    rename(columns={
        "Data Volume (GB)": "4G Data Volume (GB) L900",                        # ğŸ“Š L900 data volume
        "L.Traffic.User.VoIP.Avg": "4G Volte Traffic L900",                   # ğŸ“ VoLTE traffic L900
        "DL User Thrp (Mbps)_NUM": "DL_User_Thrp_Mbps_NUM_L900",              # â— Throughput numerator
        "DL User Thrp (Mbps)_DEN": "DL_User_Thrp_Mbps_DEN_L900",              # â— Throughput denominator
        "LTE Cell Group": "LTE_Cell_Group_L900",                              # ğŸ” Rename for clarity
        "DL User Thrp (Mbps)": "4G Throughput (Mbps) L900"                    # ğŸš€ Throughput L900
    })


# ğŸ§© Apply standardized CG names to LTE L900 data to ensure naming consistency
lte_l900_df['CG'] = lte_l900_df['LTE_Cell_Group_L900'].replace(standard_cg_mapping)
```

## ğŸ“¡âš™ï¸ 6. Load & Clean LTE L1800 Layer Data


```python
# ğŸ“¦ Load LTE L1800 layer data from ZIPs and rename columns for clarity
keyword_lte_l1800 = "(LTE_CG_DA_L1800)"

lte_l1800_df = load_gsm_from_zip_folder(zip_folder, keyword_lte_l1800, required_columns_lte).\
    rename(columns={
        "Data Volume (GB)": "4G Data Volume (GB) L1800",                         # ğŸ“Š L1800 data traffic
        "L.Traffic.User.VoIP.Avg": "4G Volte Traffic L1800",                    # ğŸ“ VoLTE traffic L1800
        "DL User Thrp (Mbps)_NUM": "DL_User_Thrp_Mbps_NUM_L1800",               # â— Throughput numerator
        "DL User Thrp (Mbps)_DEN": "DL_User_Thrp_Mbps_DEN_L1800",               # â— Throughput denominator
        "LTE Cell Group": "LTE_Cell_Group_L1800",                               # ğŸ” Standardized column name
        "DL User Thrp (Mbps)": "4G Throughput (Mbps) L1800"                      # ğŸš€ Throughput L1800
    })


# ğŸ§© Apply standardized CG names to LTE L1800 data to maintain uniform naming
lte_l1800_df['CG'] = lte_l1800_df['LTE_Cell_Group_L1800'].replace(standard_cg_mapping)
```

## ğŸ“¡ğŸ“¶ 7. Load & Clean LTE L2100 Layer Data


```python
# ğŸ“¦ Load LTE L2100 layer data and rename columns for clear identification
keyword_lte_l2100 = "(LTE_CG_DA_L2100)"

lte_l2100_df = load_gsm_from_zip_folder(zip_folder, keyword_lte_l2100, required_columns_lte).\
    rename(columns={
        "Data Volume (GB)": "4G Data Volume (GB) L2100",                         # ğŸ“Š L2100 traffic volume
        "L.Traffic.User.VoIP.Avg": "4G Volte Traffic L2100",                    # ğŸ“ VoLTE usage
        "DL User Thrp (Mbps)_NUM": "DL_User_Thrp_Mbps_NUM_L2100",               # â— Throughput numerator
        "DL User Thrp (Mbps)_DEN": "DL_User_Thrp_Mbps_DEN_L2100",               # â— Throughput denominator
        "LTE Cell Group": "LTE_Cell_Group_L2100",                               # ğŸ·ï¸ LTE cell group column
        "DL User Thrp (Mbps)": "4G Throughput (Mbps) L2100"                     # ğŸš€ Downlink throughput
    })


# ğŸ§© Apply standardized CG names to LTE L2100 data for consistent grouping across datasets
lte_l2100_df['CG'] = lte_l2100_df['LTE_Cell_Group_L2100'].replace(standard_cg_mapping)
```

## ğŸ“»ğŸ“‰ 8. Load & Clean GSM Voice Data


```python
keyword_gsm = "(GSM_CG_DA)"
required_columns_gsm = ['Date', 'TCH Availability Rate(%)', 'Globel Traffic', 'GCell Group']

gsm_df = load_gsm_from_zip_folder(zip_folder, keyword_gsm, required_columns_gsm).\
    rename(columns={
        "Globel Traffic": "2G Voice Traffic (Erl)",                   # ğŸ“ 2G voice traffic volume
        "TCH Availability Rate(%)": "TCH Availability"                # ğŸ“¶ Channel availability %
    })

# ğŸ§© Apply standardized CG names to GSM data to ensure uniform grouping across reports
gsm_df['CG'] = gsm_df['GCell Group'].replace(standard_cg_mapping)
```

## ğŸ“¡ğŸ“± 9. Load & Clean UMTS (3G) Voice & Data


```python
# ğŸ“¦ Load UMTS CG Hourly data (3G voice + data) and rename key KPIs
keyword_umts = "(UMTS_CG_DA)"
required_columns_umts = ['Date', 'UCell Group', 'VS.AMR.Erlang.BestCell_SUM', 'Data Volume (GB)']

umts_df = load_gsm_from_zip_folder(zip_folder, keyword_umts, required_columns_umts).\
    rename(columns={
        "VS.AMR.Erlang.BestCell_SUM": "3G Voice Traffic (Erl)",      # ğŸ“ 3G Voice traffic (Erlangs)
        "Data Volume (GB)": "3G Data Traffic (GB)"                   # ğŸŒ 3G Data traffic
    })
# ğŸ§© Apply standardized CG names to UMTS data to maintain consistency across all layers
umts_df['CG'] = umts_df['UCell Group'].replace(standard_cg_mapping)
```

## ğŸ”—ğŸ§© 10. Merge All Technology Layers into Unified DataFrame


```python
# ğŸ§± List of DataFrames to merge in order (UMTS + LTE layers) â€“ GSM is used as the base
dfs_to_merge = [umts_df, lte_df, lte_l900_df, lte_l1800_df, lte_l2100_df]

# ğŸ”— Merge all DataFrames on ['Date', 'Time', 'CG'] using left joins
merged_df = reduce(
    lambda left, right: pd.merge(left, right, on=['Date', 'CG'], how='left'),
    dfs_to_merge,
    gsm_df.copy()  # âš™ï¸ Start merging from GSM DataFrame
).fillna(0)        # ğŸ§¼ Replace all NaNs with 0 (assume missing = no traffic/activity)
```

## ğŸ“Š 11. Convert 4G Data Volumes from GB to TB


```python
# ğŸ”„ Convert individual band volumes
merged_df['4G_DataVolume_L900_TB'] = (merged_df['4G Data Volume (GB) L900'] / 1024)  # ğŸŸ  L900 Band
merged_df['4G_DataVolume_L1800_TB'] = (merged_df['4G Data Volume (GB) L1800'] / 1024)  # ğŸ”µ L1800 Band
merged_df['4G_DataVolume_L2100_TB'] = (merged_df['4G Data Volume (GB) L2100'] / 1024)  # ğŸŸ£ L2100 Band
# â• Calculate total 4G traffic in TB
merged_df['4G_DataVolume_TB'] = (merged_df['4G Data Traffic (GB)'] / 1024)  # ğŸ“¦ Total 4G Traffic
```

## â•ğŸ“Š 12. Calculate Total Data Volume & Total Voice Traffic â˜ï¸ğŸ“ˆ


```python
# â•ğŸ“¦ Add total data volume by summing 3G and 4G data columns (in GB)
merged_df['Total Data Volume (GB)'] = (merged_df['3G Data Traffic (GB)'] + merged_df['4G Data Traffic (GB)'])
# â•ğŸ“ Add total voice traffic by summing 2G, 3G, and VoLTE voice traffic
merged_df['Total Voice'] = (merged_df['2G Voice Traffic (Erl)'] + merged_df['3G Voice Traffic (Erl)'] + merged_df['VoLTE Traffic (Erl)'])
```

## ğŸ›¡ï¸ 13. Handles ZeroDivision & Ensures Total = 100%


```python
# ğŸ§® User-defined function to calculate band-wise percentage of 4G traffic in TB with % symbol
def adjust_percentages(row):
    total = row['4G_DataVolume_TB']
    
    if total == 0 or pd.isna(total):
        # âš ï¸ Avoid division by zero or NaN: return '0%' for all
        return pd.Series({'L1800%': '0%', 'L2100%': '0%', 'L900%': '0%'})
    
    # Step 1ï¸âƒ£: Raw exact percentages
    parts = {
        'L1800%': (row['4G_DataVolume_L1800_TB'] / total) * 100,
        'L2100%': (row['4G_DataVolume_L2100_TB'] / total) * 100,
        'L900%':  (row['4G_DataVolume_L900_TB']  / total) * 100
    }

    # Step 2ï¸âƒ£: Floor the percentages
    floored = {k: int(np.floor(v)) for k, v in parts.items()}
    remainder = {k: v - floored[k] for k, v in parts.items()}

    # Step 3ï¸âƒ£: Distribute the remaining % to top decimal fractions
    diff = 100 - sum(floored.values())
    for k in sorted(remainder, key=remainder.get, reverse=True)[:diff]:
        floored[k] += 1

    # Step 4ï¸âƒ£: Add % symbol to the final result
    formatted = {k: f"{v}%" for k, v in floored.items()}
    
    return pd.Series(formatted)

#Apply row-wise
merged_df[['L1800%', 'L2100%', 'L900%']] = merged_df.apply(adjust_percentages, axis=1)
```

## ğŸ¯ğŸ§® 14. Adjust Rounded KPI Parts to Match Total


```python
def adjust_kpi_parts(df, kpi_mapping):
    """
    ğŸ§® Adjust multiple KPI part columns so that their integer-rounded sum matches the integer-rounded total KPI.

    Parameters:
        df (pd.DataFrame): ğŸ“‹ The input DataFrame containing KPI totals and parts.
        kpi_mapping (dict): ğŸ—ºï¸ A dictionary where:
            ğŸ”‘ Keys = total KPI column names (e.g., 'VoLTE Traffic (Erl)')
            ğŸ“Œ Values = list of sub-component KPI column names (e.g., ['Volte L900', 'Volte L1800', ...])

    Returns:
        pd.DataFrame: âœ… A new DataFrame with adjusted parts so that:
                      â• Rounded total = sum of rounded parts
    """
    df_adj = df.copy()

    for total_col, part_cols in kpi_mapping.items():
        # 1ï¸âƒ£ Round total KPI to nearest integer
        total_rounded = df_adj[total_col].round().astype("Int64")

        # 2ï¸âƒ£ Floor each part (sub-KPI) and calculate remaining decimals (remainders)
        parts_float = df_adj[part_cols]
        parts_floor = parts_float.apply(np.floor)  # â¬‡ï¸ Floor values
        remainders = parts_float - parts_floor     # ğŸ” Remainder to guide rounding

        # 3ï¸âƒ£ Calculate how many units need to be added to parts to match the rounded total
        units_needed = (total_rounded - parts_floor.sum(axis=1)).astype(int)

        # 4ï¸âƒ£ Distribute missing units to the parts with the largest remainders
        adjusted_parts = parts_floor.copy()
        for i in range(len(df_adj)):
            n = units_needed[i]
            if n > 0:
                top_indices = remainders.iloc[i].nlargest(n).index  # ğŸ¥‡ Get top remainders
                adjusted_parts.loc[i, top_indices] += 1             # â• Add 1 to the top parts

        # 5ï¸âƒ£ Assign adjusted parts and final rounded total to output DataFrame
        df_adj[part_cols] = adjusted_parts.astype("Int64")  # ğŸ”¢ Ensure final integer format
        df_adj[total_col] = total_rounded                   # ğŸ§® Final total

    return df_adj
```

## ğŸ§©ğŸ“ 15. Apply KPI Part Adjustment for Rounding Consistency


```python
# ğŸ—ºï¸ Define mapping of total KPIs and their corresponding part columns
kpi_mapping = {
    "Total Data Volume (GB)": [                   # ğŸŒ Total data
        "3G Data Traffic (GB)",
        "4G Data Traffic (GB)"
    ]
}

# ğŸ§® Apply adjustment so integer-rounded sub-KPIs sum up to the rounded total KPIs
merged_df = adjust_kpi_parts(merged_df, kpi_mapping)
```

## ğŸ§© 16. KPI Part Adjustment: Ensure Parts Sum to Rounded Total (1 Decimal Accuracy)


```python
def adjust_kpi_parts_decimal(df, kpi_mapping):
    """
    ğŸ”¢ Adjust KPI parts so that their rounded values (to 1 decimal place) sum up to the rounded total KPI.

    Parameters:
        df (pd.DataFrame): ğŸ“‹ Input DataFrame with total and part KPI values.
        kpi_mapping (dict): ğŸ—ºï¸ Dict with:
            ğŸ”‘ Keys = total KPI column names
            ğŸ“Œ Values = list of part KPI column names

    Returns:
        pd.DataFrame: âœ… DataFrame with parts rounded to 1 decimal point and their sum matching the rounded total.
    """
    df_adj = df.copy()

    for total_col, part_cols in kpi_mapping.items():
        # 1ï¸âƒ£ Round total KPI to 1 decimal
        total_rounded = df_adj[total_col].round(1)

        # 2ï¸âƒ£ Floor parts to 1 decimal and calculate remainders
        parts_float = df_adj[part_cols]
        parts_floor = (parts_float * 10).apply(np.floor) / 10  # â¬‡ï¸ Floor to 1 decimal
        remainders = parts_float - parts_floor

        # 3ï¸âƒ£ Calculate how many 0.1 units are needed
        units_needed = ((total_rounded - parts_floor.sum(axis=1)) * 10).round().astype(int)

        # 4ï¸âƒ£ Distribute 0.1 to parts with highest remainder
        adjusted_parts = parts_floor.copy()
        for i in range(len(df_adj)):
            n = units_needed[i]
            if n > 0:
                top_indices = remainders.iloc[i].nlargest(n).index
                adjusted_parts.loc[i, top_indices] += 0.1

        # 5ï¸âƒ£ Round to 1 decimal just in case and assign to output
        df_adj[part_cols] = adjusted_parts.round(1)
        df_adj[total_col] = total_rounded

    return df_adj
```

## ğŸ› ï¸ 17. Apply KPI Parts Adjustment: Ensure Sub-KPIs Sum to Rounded Total (1 Decimal Precision)


```python
# ğŸ§­ Define which KPIs need part-wise adjustment
kpi_mapping1 = {
    'Total Voice': [  # ğŸ“ Voice traffic components
        "2G Voice Traffic (Erl)",
        "3G Voice Traffic (Erl)",
        "VoLTE Traffic (Erl)"
    ],
    "4G_DataVolume_TB": [  # ğŸ’¾ 4G traffic split by bands
        "4G_DataVolume_L1800_TB",
        "4G_DataVolume_L2100_TB",
        "4G_DataVolume_L900_TB"
    ]
}

# ğŸ”§ Apply decimal adjustment to ensure part KPIs sum to the rounded total
merged_df = adjust_kpi_parts_decimal(merged_df, kpi_mapping1)
```

## ğŸ§® 18. Custom Rounding Function for Flexible Decimal Precision ğŸ¯


```python
# ğŸ§® Custom Rounding Function for Flexible Decimal Precision
def round_to(x, decimals):
    try:
        return round(float(x), decimals)
    except (ValueError, TypeError):
        return x  # or np.nan
        

# ğŸ› ï¸ Define rounding precision for each target column
rounding_config = {
    '4G Overall Throughput (Mbps)': 1,
    '4G Throughput (Mbps) L900': 1,
    '4G Throughput (Mbps) L1800': 1,
    '4G Throughput (Mbps) L2100': 1
}

# ğŸ” Apply rounding column by column using the config
for col, decimals in rounding_config.items():
    merged_df[col] = merged_df[col].apply(lambda x: round_to(x, decimals))

```

## ğŸ› ï¸ 19. Function to Zero Out Metrics by Date & CG


```python
def set_columns_to_zero(df, date_values, cg_value, columns_to_zero):
    """
    Set specified columns to zero where Date is in date_values and CG matches cg_value(s).

    Parameters:
    df (pd.DataFrame): The input DataFrame
    date_values (list, set, or pd.Series): Dates to match
    cg_value (str, list, or set): CG value(s) to match
    columns_to_zero (list): Columns to set to zero

    Returns:
    pd.DataFrame: Modified DataFrame
    """
    # Ensure date_values is list-like
    if not isinstance(date_values, (list, set, pd.Series)):
        date_values = [date_values]

    # Ensure cg_value is list-like
    if not isinstance(cg_value, (list, set, pd.Series)):
        cg_value = [cg_value]

    # Create mask
    mask = df['Date'].isin(date_values) & df['CG'].isin(cg_value)
    df.loc[mask, columns_to_zero] = 0
    return df

```

## ğŸ§­ 20. Phase-3 | Cleanup of 3G/4G KPIs for Sunset Clusters


```python
updated_df = set_columns_to_zero(
    df=merged_df,
    date_values=[pd.Timestamp('2025-06-28')],
    cg_value=['2G_Sunset_NORTH_B2_SZ','2G_Sunset_N_BANNU_SZ','2G_Sunset_N_KOHAT_SZ','2G_Sunset_N_HANGU_SZ',
             'L9_South_June25_SZ','L9_South_June25_DeraAllAHYAR',
             'GSM_SZ_Center_Region_Phase_03','GSM_Dep_No_BZ_Cluster_15'],
    columns_to_zero=['3G Data Traffic (GB)','3G Voice Traffic (Erl)']
)


updated_df = set_columns_to_zero(
    df=merged_df,
    date_values=[pd.Timestamp('2025-06-27'), pd.Timestamp('2025-06-23')],
    cg_value=['2G_Sunset_NORTH_B2_SZ','2G_Sunset_N_BANNU_SZ','2G_Sunset_N_KOHAT_SZ','2G_Sunset_N_HANGU_SZ',
             'L9_South_June25_SZ','L9_South_June25_DeraAllAHYAR'],
    columns_to_zero=['4G Throughput (Mbps) L900','4G_DataVolume_L900_TB']
)

updated_df = set_columns_to_zero(
    df=merged_df,
    date_values=[pd.Timestamp('2025-06-27')],
    cg_value=['GSM_Dep_No_BZ_Cluster_15'],
    columns_to_zero=['4G Throughput (Mbps) L2100']
)
```

## ğŸ§­ 21. Phase-4 | Cleanup of 3G/4G KPIs for Sunset Clusters


```python
updated_df = set_columns_to_zero(
    df=merged_df,
    date_values=[pd.Timestamp('2025-07-10')],
    cg_value=['Sunset_NORTH_B3_SZ','Sunset_N_PESHAWAR_SZ',
    'SZ_Dep_Cluster_9','Sunset_SIALKOT',
    'South_July25_2G_P4_SZ','South_July25_2G_Lark_city'],
    columns_to_zero=['3G Data Traffic (GB)','3G Voice Traffic (Erl)']
)

updated_df = set_columns_to_zero(
    df=merged_df,
    date_values=[pd.Timestamp('2025-07-09')],
    cg_value=['Sunset_NORTH_B3_SZ','Sunset_N_PESHAWAR_SZ',
    'SZ_Dep_Cluster_9','Sunset_SIALKOT',
    'South_July25_2G_P4_SZ','South_July25_2G_Lark_city'],
    columns_to_zero=['4G Throughput (Mbps) L900','4G_DataVolume_L900_TB']
)
```

## ğŸ“¤ 22. Export Processed DataFrame


```python
path = 'D:/Advance_Data_Sets/PPT_Sunset_NW'                    # ğŸ“ Set working directory path for data and templates
os.chdir(path)                                                 # ğŸ”„ Change current working directory to the specified path
merged_df.to_csv('kpi_checking.csv',index=False)
```

## ğŸ“Š 23. Final Selection of Key KPIs for Reporting & Export ğŸ“


```python
# ğŸ§± Filter and organize required columns from the merged DataFrame
merged_df1 = merged_df[[
    'Date',                                    # ğŸ“… Date of record
    'CG',                                      # ğŸ—‚ï¸ Cell Group
    'Total Voice',                             # â˜ï¸ Total Voice Traffic (all tech)
    "2G Voice Traffic (Erl)",                  # 2ï¸âƒ£ 2G Voice
    "3G Voice Traffic (Erl)",                  # 3ï¸âƒ£ 3G Voice
    'VoLTE Traffic (Erl)',                     # ğŸ“¶ VoLTE Traffic
    'Total Data Volume (GB)',                  # ğŸ“¦ Total Data in GB
    '3G Data Traffic (GB)',                    # 3ï¸âƒ£ 3G Data in GB
    '4G Data Traffic (GB)',                    # 4ï¸âƒ£ 4G Data in GB
    
    # ğŸ“ Converted TB values per 4G band
    '4G_DataVolume_TB',
    '4G_DataVolume_L1800_TB',
    '4G_DataVolume_L2100_TB',
    '4G_DataVolume_L900_TB',
    
    # âš¡ Throughput KPIs
    '4G Overall Throughput (Mbps)',
    '4G Throughput (Mbps) L900',
    '4G Throughput (Mbps) L1800',
    '4G Throughput (Mbps) L2100',

    # ğŸ“ˆ Band-wise Share %
    'L1800%',
    'L2100%',
    'L900%'
]]
```

## ğŸ§  24. Extract Max Date Rows & Create Dynamic CG-Based Variables


```python
# ğŸ“… Step 1: Filter rows where Date is maximum
result = merged_df1.loc[
    merged_df1['Date'] == merged_df1['Date'].max(), 
    ['Date', 'CG', 'L1800%', 'L2100%', 'L900%']  # ğŸ¯ Select only key columns
]

# ğŸ” Step 2: Loop through each CG and create dynamic variable like share_<CG>
for cg in result['CG'].unique():
    # ğŸ§¼ Clean CG name to make it a valid Python variable (no spaces or hyphens)
    safe_cg = cg.replace(" ", "_").replace("-", "_")

    # ğŸ·ï¸ Construct variable name like: share_L9_South_June25_SZ
    var_name = f"share_{safe_cg}"

    # ğŸ§ª Filter DataFrame for this CG and assign it to a dynamic global variable
    globals()[var_name] = result[result['CG'] == cg][['Date', 'CG', 'L1800%', 'L2100%', 'L900%']]
```

## ğŸ§ ğŸ” 25. User-Defined Function: Filter DataFrame by Date, CG List, and Selected Columns ğŸ“…ğŸ—‚ï¸


```python
# ğŸ§ ğŸ” User-Defined Function: Filter DataFrame by Date, CG List, and Selected Columns ğŸ“…ğŸ—‚ï¸
def filter_by_date_and_columns(df, date_col, start_date, columns_to_keep, rename_dict=None, cg_list=None):
    """
    ğŸ“… Filters a DataFrame based on date and CG list, and selects/renames columns.

    Parameters:
    - df: pandas.DataFrame ğŸ“Š Input dataset
    - date_col: str ğŸ—“ï¸ Name of the date column
    - start_date: str or datetime â³ Minimum date to include
    - columns_to_keep: list[str] âœ… Columns to retain in output
    - rename_dict: dict, optional âœï¸ Rename mapping {old_name: new_name}
    - cg_list: list[str], optional ğŸ·ï¸ Cell Group names to filter

    Returns:
    - pandas.DataFrame ğŸ§¾ Filtered and optionally renamed DataFrame
    """
    # ğŸ—“ï¸ Filter rows where the date is on or after the specified start_date
    filtered_df = df[df[date_col] >= pd.to_datetime(start_date)]

    # ğŸ·ï¸ Apply CG filtering if cg_list is provided and 'CG' column exists
    if cg_list and 'CG' in filtered_df.columns:
        filtered_df = filtered_df[filtered_df['CG'].isin(cg_list)]

    # ğŸ“‘ Retain only columns that exist in the DataFrame
    columns_to_keep = [col for col in columns_to_keep if col in filtered_df.columns]
    filtered_df = filtered_df[columns_to_keep]

    # âœï¸ Optionally rename columns using rename_dict
    if rename_dict:
        rename_dict = {k: v for k, v in rename_dict.items() if k in filtered_df.columns}
        filtered_df = filtered_df.rename(columns=rename_dict)

    # âœ… Return the cleaned and filtered DataFrame
    return filtered_df
```

## ğŸ”ğŸ“¦ 26. User-Defined Function: Filter and Combine Multiple CG Groups into One DataFrame ğŸ§¾ğŸ§©


```python
# ğŸ§ ğŸ” User-Defined Function: Filter DataFrame by Date, CG List, and Selected Columns ğŸ“…ğŸ—‚ï¸
def filter_by_date_and_columns(df, date_col, start_date, columns_to_keep, rename_dict=None, cg_list=None):
    """
    ğŸ“… Filters a DataFrame based on date and CG list, and selects/renames columns.

    Parameters:
    - df: pandas.DataFrame ğŸ“Š Input dataset
    - date_col: str ğŸ—“ï¸ Name of the date column
    - start_date: str or datetime â³ Minimum date to include
    - columns_to_keep: list[str] âœ… Columns to retain in output
    - rename_dict: dict, optional âœï¸ Rename mapping {old_name: new_name}
    - cg_list: list[str], optional ğŸ·ï¸ Cell Group names to filter

    Returns:
    - pandas.DataFrame ğŸ§¾ Filtered and optionally renamed DataFrame
    """
    # ğŸ—“ï¸ Filter rows where the date is on or after the specified start_date
    filtered_df = df[df[date_col] >= pd.to_datetime(start_date)]

    # ğŸ·ï¸ Apply CG filtering if cg_list is provided and 'CG' column exists
    if cg_list and 'CG' in filtered_df.columns:
        filtered_df = filtered_df[filtered_df['CG'].isin(cg_list)]

    # ğŸ“‘ Retain only columns that exist in the DataFrame
    columns_to_keep = [col for col in columns_to_keep if col in filtered_df.columns]
    filtered_df = filtered_df[columns_to_keep]

    # âœï¸ Optionally rename columns using rename_dict
    if rename_dict:
        rename_dict = {k: v for k, v in rename_dict.items() if k in filtered_df.columns}
        filtered_df = filtered_df.rename(columns=rename_dict)

    # âœ… Return the cleaned and filtered DataFrame
    return filtered_df
```

## ğŸ“¦ğŸ”§ 27. Configuration & Execution: Filter Multiple CG Groups by Date and KPIs ğŸ—‚ï¸ğŸ“Š


```python
# ğŸ”ğŸ“¦ User-Defined Function: Filter and Combine Multiple CG Groups into One DataFrame ğŸ§¾ğŸ§©
def filter_multiple_cg_groups(df, date_col, cg_groups, columns_to_keep, rename_dict=None):
    """
    ğŸ” Applies `filter_by_date_and_columns` to multiple CG groups and combines the results.

    Parameters:
    - df: pandas.DataFrame ğŸ“Š Input dataset
    - date_col: str ğŸ—“ï¸ Name of the date column
    - cg_groups: list[dict] ğŸ“¦ Each group should contain:
        - 'name': str ğŸ·ï¸ Optional group label (e.g. "Phase 2")
        - 'cg_list': list[str] â• Cell Groups to include
        - 'start_date': str or datetime â³ Start date for filtering
    - columns_to_keep: list[str] âœ… Columns to retain in each group
    - rename_dict: dict, optional âœï¸ Rename mapping {old: new}

    Returns:
    - pandas.DataFrame ğŸ§¾ Combined and labeled data from all CG groups
    """
    combined = pd.concat([
        # âœ… Ensure 'CG' is included without duplication
        filter_by_date_and_columns(
            df=df,
            date_col=date_col,
            start_date=group['start_date'],
            columns_to_keep=(columns_to_keep if 'CG' in columns_to_keep else columns_to_keep + ['CG']),
            rename_dict=rename_dict,
            cg_list=group['cg_list']
        ).assign(Group=group.get('name', 'Unknown'))  # ğŸ·ï¸ Add group name column
        for group in cg_groups
    ], ignore_index=True)  # ğŸ”„ Combine all into a single DataFrame

    return combined
```

## ğŸ“¦ğŸ”§ 28. Configuration & Execution: Filter Multiple CG Groups by Date and KPIs ğŸ—‚ï¸ğŸ“Š


```python
# ğŸ—ƒï¸ Define CG group configurations with labels and filtering start dates
cg_groups = [
    {
        "name": "Phase 3",  
        "cg_list": [
            'L9_South_June25_SZ', 'L9_South_June25_DeraAllAHYAR',
            '2G_Sunset_NORTH_B2_SZ', '2G_Sunset_N_KOHAT_SZ',
            '2G_Sunset_N_HANGU_SZ', '2G_Sunset_N_BANNU_SZ',
            'GSM_BZ_Center_Region_Phase-03',
            'GSM_Dep_Cluster_120', 'GSM_Dep_Cluster_121',
            'GSM_Dep_Cluster_80', 'GSM_Dep_No_BZ_Cluster_15',
            'GSM_Dep_No_BZ_Cluster_19', 'GSM_Dep_No_BZ_Cluster_33',
            'GSM_Dep_No_BZ_Cluster_41', 'GSM_Dep_No_BZ_Cluster_50',
            'GSM_Dep_No_BZ_Cluster_54', 'GSM_Dep_No_BZ_Cluster_64',
            'GSM_SZ_BZ_Center_Region_Phase-03', 'GSM_SZ_Center_Region_Phase_03'
        ],
        "start_date": '2025-06-01'  
    },
    {
        "name": "Phase 2",
        "cg_list": [
            'L9_Jacobabad_Apr25_2G', 'L9_Control_Shikarpur_2G', 'L9_Khuzdar_SZ_2G',
            'L9_Control_MajCitiesBaluchistan_2G', 'L9_Hub_Apr25_2G_SZ',
            'HUB_Control_2G', 'L9_Turbat_Apr25_2G_SZ', 'L2100_Gwadar_2G_City'
        ],
        "start_date": '2025-04-01'
    },
    {
        "name": "Phase 4", 
        "cg_list": [
            'SZ_Dep_Cluster_9', 'Sunset_SAMBRIAL', 'Sunset_SIALKOT',
            'Sunset_N_PESHAWAR_SZ', 'Sunset_NORTH_B3_SZ',
            'South_July25_2G_P4_SZ','South_July25_2G_Lark_city',
        ],
        "start_date": '2025-06-10'
    },

        {
        "name": "Phase 5",
        "cg_list": [
         'SZ_Center_Phase V','DG_KHAN_City',
            'South_July25_22nd Batch_SZ',
            'South_July25_Shahdadkot_city_SZ'
        ],
        "start_date": '2025-06-22'
    },
    {
        "name": "Phase 6",
        "cg_list": [
            'SZ_Center_Phase VI', 
            'DI_KHAN_City'
        ],
        "start_date": '2025-06-29'
    }
]


# ğŸ“‘ Define the columns to retain for analysis and reporting
columns_to_keep = [
    'Date', 'CG', 'Total Voice', '2G Voice Traffic (Erl)', '3G Voice Traffic (Erl)', 'VoLTE Traffic (Erl)',
    'Total Data Volume (GB)', '3G Data Traffic (GB)', '4G Data Traffic (GB)', '4G_DataVolume_TB',
    '4G_DataVolume_L1800_TB', '4G_DataVolume_L2100_TB', '4G_DataVolume_L900_TB',
    '4G Overall Throughput (Mbps)', '4G Throughput (Mbps) L900',
    '4G Throughput (Mbps) L1800', '4G Throughput (Mbps) L2100'
]

# âœï¸ Define column renaming rules for clarity
rename_dict = {
    'Date': 'Date',
    '2G Voice Traffic (Erl)': '2G Voice',
    '3G Voice Traffic (Erl)': '3G Voice',
    'VoLTE Traffic (Erl)': 'VoLTE',
    'Total Voice': 'Total Voice',
    '3G Data Traffic (GB)': '3G Data Volume (GB)',
    '4G Data Traffic (GB)': '4G Data Volume (GB)',
    'Total Data Volume (GB)': 'Data Volume'
}

# ğŸš€ Execute the filtering across all CG groups and combine the results
filtered_all = filter_multiple_cg_groups(
    df=merged_df1,                     # ğŸ“Š Input DataFrame
    date_col='Date',                   # ğŸ“… Column to filter by date
    cg_groups=cg_groups,               # ğŸ“¦ CG group configurations
    columns_to_keep=columns_to_keep,   # âœ… Selected columns
    rename_dict=rename_dict            # âœï¸ Rename mapping
)
```

## ğŸ“ŠğŸ§± 29. CG-wise Split: Voice, Data, Layer Volumes, and Throughput


```python
# ğŸ”ğŸ“Š User-Defined Function: Extract Views for a Single CG from DataFrame
def extract_cg_views(df, cg_name):
    """
    ğŸ“Š Returns structured views (dataframes) for a given CG name:
    - Voice traffic
    - Total data
    - Layer-wise 4G data volume
    - Layer-wise 4G throughput

    Parameters:
    - df: pandas.DataFrame with filtered/renamed columns (must include 'CG' column)
    - cg_name: str â¡ï¸ Name of the CG to extract

    Returns:
    - dict of DataFrames: {'voice': ..., 'data': ..., 'volume': ..., 'throughput': ...}
    """
    # ğŸ¯ Filter data for the specified CG
    df_cg = df[df['CG'] == cg_name]

    # ğŸ—£ï¸ Voice Traffic View
    df_voice = df_cg[['Date', '2G Voice', '3G Voice', 'VoLTE', 'Total Voice']]

    # ğŸ“¶ Data Traffic View
    df_data = df_cg[['Date', '3G Data Volume (GB)', '4G Data Volume (GB)', 'Data Volume']]

    # ğŸ“¦ Layer-wise 4G Data Volume View
    df_volume = (
        df_cg[['Date', '4G_DataVolume_L900_TB', '4G_DataVolume_L1800_TB',
               '4G_DataVolume_L2100_TB', '4G_DataVolume_TB']]
        .rename(columns={
            '4G_DataVolume_L900_TB': 'L900',
            '4G_DataVolume_L1800_TB': 'L1800',
            '4G_DataVolume_L2100_TB': 'L2100',
            '4G_DataVolume_TB': 'Total'
        })
        [['Date', 'L1800', 'L2100', 'L900', 'Total']]
    )

    # ğŸš€ Layer-wise 4G Throughput View
    df_throughput = (
        df_cg[['Date', '4G Overall Throughput (Mbps)', '4G Throughput (Mbps) L900',
               '4G Throughput (Mbps) L1800', '4G Throughput (Mbps) L2100']]
        .rename(columns={
            '4G Overall Throughput (Mbps)': 'Overall',
            '4G Throughput (Mbps) L900': 'L900',
            '4G Throughput (Mbps) L1800': 'L1800',
            '4G Throughput (Mbps) L2100': 'L2100'
        })
        [['Date', 'Overall', 'L1800', 'L2100', 'L900']]
    )

    # ğŸ“¦ Return all structured views in a dictionary
    return {
        'voice': df_voice,
        'data': df_data,
        'volume': df_volume,
        'throughput': df_throughput
    }

```

## ğŸ§¬ 30. Apply Dynamic View Creation for Each CG and Rename 'Date' â¡ï¸ 'Row Labels'


```python
# ğŸ“¦ Step 1: Extract unique CGs from filtered DataFrame
cg_list = filtered_all['CG'].unique().tolist()

# ğŸ—‚ï¸ Initialize view dictionaries
voice_views = {}
data_views = {}
volume_views = {}
throughput_views = {}

# ğŸ” Extract views for each CG using the updated function
for cg in cg_list:
    result = extract_cg_views(filtered_all, cg)
    voice_views[cg] = result['voice']
    data_views[cg] = result['data']
    volume_views[cg] = result['volume']
    throughput_views[cg] = result['throughput']

# ğŸ§  Step 2: Dynamically assign views to variables and rename 'Date' â¡ï¸ 'Row Labels'
for cg in cg_list:
    var_suffix = cg.lower().replace('-', '_').replace(' ', '_')

    # ğŸ¯ Assign to dynamic variable names
    locals()[f"voice_{var_suffix}"] = voice_views[cg]
    locals()[f"data_{var_suffix}"] = data_views[cg]
    locals()[f"volume_{var_suffix}"] = volume_views[cg]
    locals()[f"throughput_{var_suffix}"] = throughput_views[cg]

    # âœï¸ Rename 'Date' column to 'Row Labels'
    for view_type in ['voice', 'data', 'volume', 'throughput']:
        view_var = locals()[f"{view_type}_{var_suffix}"]
        if 'Date' in view_var.columns:
            view_var.rename(columns={'Date': 'Row Labels'}, inplace=True)
```

## ğŸ”ğŸ“¦ 31. Identify All CG-Specific DataFrames by Type (Voice, Data, Volume, Throughput)


```python
[v for v in locals() if v.startswith('voice_')]         # ğŸ—£ï¸ Find all local variables related to voice traffic
```




    ['voice_views',
     'voice_2g_sunset_north_b2_sz',
     'voice_2g_sunset_n_bannu_sz',
     'voice_2g_sunset_n_hangu_sz',
     'voice_2g_sunset_n_kohat_sz',
     'voice_gsm_bz_center_region_phase_03',
     'voice_gsm_dep_cluster_120',
     'voice_gsm_dep_cluster_121',
     'voice_gsm_dep_cluster_80',
     'voice_gsm_dep_no_bz_cluster_15',
     'voice_gsm_dep_no_bz_cluster_19',
     'voice_gsm_dep_no_bz_cluster_33',
     'voice_gsm_dep_no_bz_cluster_41',
     'voice_gsm_dep_no_bz_cluster_50',
     'voice_gsm_dep_no_bz_cluster_54',
     'voice_gsm_dep_no_bz_cluster_64',
     'voice_gsm_sz_bz_center_region_phase_03',
     'voice_gsm_sz_center_region_phase_03',
     'voice_l9_south_june25_sz',
     'voice_l9_south_june25_deraallahyar',
     'voice_l9_jacobabad_apr25_2g',
     'voice_l9_hub_apr25_2g_sz',
     'voice_l9_turbat_apr25_2g_sz',
     'voice_l9_khuzdar_sz_2g',
     'voice_l9_control_majcitiesbaluchistan_2g',
     'voice_l9_control_shikarpur_2g',
     'voice_l2100_gwadar_2g_city',
     'voice_hub_control_2g',
     'voice_sunset_n_peshawar_sz',
     'voice_sunset_north_b3_sz',
     'voice_sz_dep_cluster_9',
     'voice_sunset_sambrial',
     'voice_sunset_sialkot',
     'voice_south_july25_2g_p4_sz',
     'voice_south_july25_2g_lark_city',
     'voice_sz_center_phase_v',
     'voice_dg_khan_city',
     'voice_south_july25_22nd_batch_sz',
     'voice_south_july25_shahdadkot_city_sz',
     'voice_sz_center_phase_vi',
     'voice_di_khan_city']




```python
[v for v in locals() if v.startswith('data_')]          # ğŸ“¶ Find all local variables related to total data traffic
```




    ['data_views',
     'data_2g_sunset_north_b2_sz',
     'data_2g_sunset_n_bannu_sz',
     'data_2g_sunset_n_hangu_sz',
     'data_2g_sunset_n_kohat_sz',
     'data_gsm_bz_center_region_phase_03',
     'data_gsm_dep_cluster_120',
     'data_gsm_dep_cluster_121',
     'data_gsm_dep_cluster_80',
     'data_gsm_dep_no_bz_cluster_15',
     'data_gsm_dep_no_bz_cluster_19',
     'data_gsm_dep_no_bz_cluster_33',
     'data_gsm_dep_no_bz_cluster_41',
     'data_gsm_dep_no_bz_cluster_50',
     'data_gsm_dep_no_bz_cluster_54',
     'data_gsm_dep_no_bz_cluster_64',
     'data_gsm_sz_bz_center_region_phase_03',
     'data_gsm_sz_center_region_phase_03',
     'data_l9_south_june25_sz',
     'data_l9_south_june25_deraallahyar',
     'data_l9_jacobabad_apr25_2g',
     'data_l9_hub_apr25_2g_sz',
     'data_l9_turbat_apr25_2g_sz',
     'data_l9_khuzdar_sz_2g',
     'data_l9_control_majcitiesbaluchistan_2g',
     'data_l9_control_shikarpur_2g',
     'data_l2100_gwadar_2g_city',
     'data_hub_control_2g',
     'data_sunset_n_peshawar_sz',
     'data_sunset_north_b3_sz',
     'data_sz_dep_cluster_9',
     'data_sunset_sambrial',
     'data_sunset_sialkot',
     'data_south_july25_2g_p4_sz',
     'data_south_july25_2g_lark_city',
     'data_sz_center_phase_v',
     'data_dg_khan_city',
     'data_south_july25_22nd_batch_sz',
     'data_south_july25_shahdadkot_city_sz',
     'data_sz_center_phase_vi',
     'data_di_khan_city']




```python
[v for v in locals() if v.startswith('volume_')]        # ğŸ§± Find all local variables related to 4G layer-wise data volume
```




    ['volume_views',
     'volume_2g_sunset_north_b2_sz',
     'volume_2g_sunset_n_bannu_sz',
     'volume_2g_sunset_n_hangu_sz',
     'volume_2g_sunset_n_kohat_sz',
     'volume_gsm_bz_center_region_phase_03',
     'volume_gsm_dep_cluster_120',
     'volume_gsm_dep_cluster_121',
     'volume_gsm_dep_cluster_80',
     'volume_gsm_dep_no_bz_cluster_15',
     'volume_gsm_dep_no_bz_cluster_19',
     'volume_gsm_dep_no_bz_cluster_33',
     'volume_gsm_dep_no_bz_cluster_41',
     'volume_gsm_dep_no_bz_cluster_50',
     'volume_gsm_dep_no_bz_cluster_54',
     'volume_gsm_dep_no_bz_cluster_64',
     'volume_gsm_sz_bz_center_region_phase_03',
     'volume_gsm_sz_center_region_phase_03',
     'volume_l9_south_june25_sz',
     'volume_l9_south_june25_deraallahyar',
     'volume_l9_jacobabad_apr25_2g',
     'volume_l9_hub_apr25_2g_sz',
     'volume_l9_turbat_apr25_2g_sz',
     'volume_l9_khuzdar_sz_2g',
     'volume_l9_control_majcitiesbaluchistan_2g',
     'volume_l9_control_shikarpur_2g',
     'volume_l2100_gwadar_2g_city',
     'volume_hub_control_2g',
     'volume_sunset_n_peshawar_sz',
     'volume_sunset_north_b3_sz',
     'volume_sz_dep_cluster_9',
     'volume_sunset_sambrial',
     'volume_sunset_sialkot',
     'volume_south_july25_2g_p4_sz',
     'volume_south_july25_2g_lark_city',
     'volume_sz_center_phase_v',
     'volume_dg_khan_city',
     'volume_south_july25_22nd_batch_sz',
     'volume_south_july25_shahdadkot_city_sz',
     'volume_sz_center_phase_vi',
     'volume_di_khan_city']




```python
[v for v in locals() if v.startswith('throughput_')]    # ğŸš€ Find all local variables related to 4G throughput KPIs
```




    ['throughput_views',
     'throughput_2g_sunset_north_b2_sz',
     'throughput_2g_sunset_n_bannu_sz',
     'throughput_2g_sunset_n_hangu_sz',
     'throughput_2g_sunset_n_kohat_sz',
     'throughput_gsm_bz_center_region_phase_03',
     'throughput_gsm_dep_cluster_120',
     'throughput_gsm_dep_cluster_121',
     'throughput_gsm_dep_cluster_80',
     'throughput_gsm_dep_no_bz_cluster_15',
     'throughput_gsm_dep_no_bz_cluster_19',
     'throughput_gsm_dep_no_bz_cluster_33',
     'throughput_gsm_dep_no_bz_cluster_41',
     'throughput_gsm_dep_no_bz_cluster_50',
     'throughput_gsm_dep_no_bz_cluster_54',
     'throughput_gsm_dep_no_bz_cluster_64',
     'throughput_gsm_sz_bz_center_region_phase_03',
     'throughput_gsm_sz_center_region_phase_03',
     'throughput_l9_south_june25_sz',
     'throughput_l9_south_june25_deraallahyar',
     'throughput_l9_jacobabad_apr25_2g',
     'throughput_l9_hub_apr25_2g_sz',
     'throughput_l9_turbat_apr25_2g_sz',
     'throughput_l9_khuzdar_sz_2g',
     'throughput_l9_control_majcitiesbaluchistan_2g',
     'throughput_l9_control_shikarpur_2g',
     'throughput_l2100_gwadar_2g_city',
     'throughput_hub_control_2g',
     'throughput_sunset_n_peshawar_sz',
     'throughput_sunset_north_b3_sz',
     'throughput_sz_dep_cluster_9',
     'throughput_sunset_sambrial',
     'throughput_sunset_sialkot',
     'throughput_south_july25_2g_p4_sz',
     'throughput_south_july25_2g_lark_city',
     'throughput_sz_center_phase_v',
     'throughput_dg_khan_city',
     'throughput_south_july25_22nd_batch_sz',
     'throughput_south_july25_shahdadkot_city_sz',
     'throughput_sz_center_phase_vi',
     'throughput_di_khan_city']



## ğŸ—‚ï¸ğŸ“Š 32. Load PowerPoint template for chart updates 


```python
path = 'D:/Advance_Data_Sets/PPT_Sunset_NW'                    # ğŸ“ Set working directory path for data and templates
os.chdir(path)                                                 # ğŸ”„ Change current working directory to the specified path
prs_phase3 = Presentation('template_phase3.pptx')              # ğŸ“Š Load PowerPoint template for Phase-3
prs_phase4 = Presentation('template_phase4.pptx')              # ğŸ“Š Load PowerPoint template for Phase-4
```

## ğŸ§© 33. User-Defined Function to Update PowerPoint Chart with DataFrame


```python
def update_chart(prs, slide_index, shape_index, dataframe):
    # ğŸ“Š Initialize a new chart data object
    chart_data = CategoryChartData()
    # ğŸ·ï¸ Set categories (typically X-axis labels) using the first column
    chart_data.categories = dataframe['Row Labels']
    # ğŸ“ˆ Add each series (data columns) to the chart, skipping the category column
    for col in dataframe.columns[1:]:  # Skip 'Row Labels'
        chart_data.add_series(col, dataframe[col])
    # ğŸ“„ Access the specific slide by index
    slide = prs.slides[slide_index]
    # ğŸ”³ Access the specific shape on the slide (assumed to be a chart)
    chart_shape = slide.shapes[shape_index]
    # ğŸ§  Extract the chart object from the shape
    chart = chart_shape.chart
    # ğŸ”„ Replace existing chart data with the new data
    chart.replace_data(chart_data)
```

## ğŸ“ 34. Update Table Cells in PowerPoint Slide ğŸ“Š


```python
def update_table_cells(prs, slide_index, table_index, updates, force_formatting=False):
    """
    Update table cell text in a specific table on a specific slide.

    Parameters:
    - prs : Presentation object
    - slide_index : int, slide number (0-based)
    - table_index : int, table number on slide (0-based)
    - updates : list of tuples (row, col, new_text)
    - force_formatting : bool, if True apply Calibri 11pt bold white center formatting
    """

    slide = prs.slides[slide_index]

    # Get all tables on the slide
    tables = [shape.table for shape in slide.shapes if shape.shape_type == MSO_SHAPE_TYPE.TABLE]

    if table_index >= len(tables):
        print(f"No table at index {table_index} on slide {slide_index}")
        return

    table = tables[table_index]

    for row, col, new_text in updates:
        try:
            cell = table.cell(row, col)
            paragraph = cell.text_frame.paragraphs[0]

            if paragraph.runs:
                run = paragraph.runs[0]
                run.text = new_text
            else:
                # If no runs exist, set text normally
                cell.text = new_text
                paragraph = cell.text_frame.paragraphs[0]
                run = paragraph.runs[0]

            if force_formatting:
                run.font.name = 'Calibri'
                run.font.size = Pt(11)
                run.font.bold = True
                run.font.color.rgb = RGBColor(255, 255, 255)  # white
                paragraph.alignment = PP_ALIGN.CENTER

        except IndexError:
            print(f"Cell at row {row}, col {col} does not exist.")
```

## ğŸ” 35. Reusing User-Defined Function to Update Slide Charts

### 35.1 Phase-3 PPT Charts Update


```python
# ğŸ“ˆ North - Phase-3 Charts

# ğŸ“Š Data: 2G Sunset - North B2 SZ & Bannu SZ (Slide 2)
update_chart(prs=prs_phase3, slide_index=2, shape_index=1, dataframe=data_2g_sunset_north_b2_sz)    # ğŸ—ºï¸ North B2 SZ - 2G Sunset Data
update_chart(prs=prs_phase3, slide_index=2, shape_index=0, dataframe=data_2g_sunset_n_bannu_sz)     # ğŸ—ºï¸ Bannu SZ - 2G Sunset Data

# ğŸ“Š Data: 2G Sunset - Kohat SZ & Hangu SZ (Slide 3)
update_chart(prs=prs_phase3, slide_index=3, shape_index=1, dataframe=data_2g_sunset_n_kohat_sz)     # ğŸ—ºï¸ Kohat SZ - 2G Sunset Data
update_chart(prs=prs_phase3, slide_index=3, shape_index=0, dataframe=data_2g_sunset_n_hangu_sz)     # ğŸ—ºï¸ Hangu SZ - 2G Sunset Data

# ğŸ“¦ Volume: 2G Sunset - North B2 SZ & Bannu SZ (Slide 4)
update_chart(prs=prs_phase3, slide_index=4, shape_index=5, dataframe=volume_2g_sunset_north_b2_sz)  # ğŸ§® North B2 SZ - Volume Data
update_chart(prs=prs_phase3, slide_index=4, shape_index=4, dataframe=volume_2g_sunset_n_bannu_sz)   # ğŸ§® Bannu SZ - Volume Data

# ğŸ“¦ Volume: 2G Sunset - Kohat SZ & Hangu SZ (Slide 5)
update_chart(prs=prs_phase3, slide_index=5, shape_index=5, dataframe=volume_2g_sunset_n_kohat_sz)   # ğŸ§® Kohat SZ - Volume Data
update_chart(prs=prs_phase3, slide_index=5, shape_index=4, dataframe=volume_2g_sunset_n_hangu_sz)   # ğŸ§® Hangu SZ - Volume Data

# ğŸš€ Throughput: 2G Sunset - North B2 SZ & Bannu SZ (Slide 6) just change this one
update_chart(prs=prs_phase3, slide_index=6, shape_index=3, dataframe=throughput_2g_sunset_north_b2_sz)  # ğŸš€ North B2 SZ - Throughput
update_chart(prs=prs_phase3, slide_index=6, shape_index=0, dataframe=throughput_2g_sunset_n_bannu_sz)   # ğŸš€ Bannu SZ - Throughput

# ğŸš€ Throughput: 2G Sunset - Kohat SZ & Hangu SZ (Slide 7)
update_chart(prs=prs_phase3, slide_index=7, shape_index=1, dataframe=throughput_2g_sunset_n_kohat_sz)   # ğŸš€ Kohat SZ - Throughput
update_chart(prs=prs_phase3, slide_index=7, shape_index=0, dataframe=throughput_2g_sunset_n_hangu_sz)   # ğŸš€ Hangu SZ - Throughput

# ğŸ“ Voice: 2G Sunset - North B2 SZ & Bannu SZ (Slide 8)
update_chart(prs=prs_phase3, slide_index=8, shape_index=4, dataframe=voice_2g_sunset_north_b2_sz)       # ğŸ“ North B2 SZ - Voice
update_chart(prs=prs_phase3, slide_index=8, shape_index=3, dataframe=voice_2g_sunset_n_bannu_sz)        # ğŸ“ Bannu SZ - Voice

# ğŸ“ Voice: 2G Sunset - Kohat SZ & Hangu SZ (Slide 9)
update_chart(prs=prs_phase3, slide_index=9, shape_index=1, dataframe=voice_2g_sunset_n_kohat_sz)        # ğŸ“ Kohat SZ - Voice
update_chart(prs=prs_phase3, slide_index=9, shape_index=0, dataframe=voice_2g_sunset_n_hangu_sz)        # ğŸ“ Hangu SZ - Voice
```


```python
# ğŸ“ˆ South - Phase-3 Charts

# ğŸ“Š Data: L9 South June25 SZ & Dera Allahyar (Slide 11)
update_chart(prs=prs_phase3, slide_index=11, shape_index=1, dataframe=data_l9_south_june25_sz)             # ğŸ—ºï¸ L9 South SZ - 2G Sunset Data
update_chart(prs=prs_phase3, slide_index=11, shape_index=0, dataframe=data_l9_south_june25_deraallahyar)   # ğŸ—ºï¸ Dera Allahyar - 2G Sunset Data

# ğŸ“¦ Volume: L9 South June25 SZ & Dera Allahyar (Slide 12)
update_chart(prs=prs_phase3, slide_index=12, shape_index=5, dataframe=volume_l9_south_june25_sz)           # ğŸ§® L9 South SZ - Volume
update_chart(prs=prs_phase3, slide_index=12, shape_index=4, dataframe=volume_l9_south_june25_deraallahyar) # ğŸ§® Dera Allahyar - Volume

# ğŸš€ Throughput: L9 South June25 SZ & Dera Allahyar (Slide 13)
update_chart(prs=prs_phase3, slide_index=13, shape_index=4, dataframe=throughput_l9_south_june25_sz)       # ğŸš€ L9 South SZ - Throughput
update_chart(prs=prs_phase3, slide_index=13, shape_index=3, dataframe=throughput_l9_south_june25_deraallahyar) # ğŸš€ Dera Allahyar - Throughput

# ğŸ“ Voice: L9 South June25 SZ & Dera Allahyar (Slide 14)
update_chart(prs=prs_phase3, slide_index=14, shape_index=4, dataframe=voice_l9_south_june25_sz)            # ğŸ“ L9 South SZ - Voice
update_chart(prs=prs_phase3, slide_index=14, shape_index=3, dataframe=voice_l9_south_june25_deraallahyar)  # ğŸ“ Dera Allahyar - Voice
```


```python
# ğŸ™ï¸ Center - Phase-3 Charts

# ğŸ“Š Data: GSM SZ Center Region & Dep No BZ Cluster 15 (Slide 16)
update_chart(prs=prs_phase3, slide_index=16, shape_index=1, dataframe=data_gsm_sz_center_region_phase_03)        # ğŸ—ºï¸ Center Region - GSM Data
update_chart(prs=prs_phase3, slide_index=16, shape_index=0, dataframe=data_gsm_dep_no_bz_cluster_15)             # ğŸ—ºï¸ Dep No BZ Cluster 15 - GSM Data

# ğŸ“¦ Volume: GSM SZ Center Region & Dep No BZ Cluster 15 (Slide 17)
update_chart(prs=prs_phase3, slide_index=17, shape_index=4, dataframe=volume_gsm_sz_center_region_phase_03)      # ğŸ§® Center Region - Volume
update_chart(prs=prs_phase3, slide_index=17, shape_index=3, dataframe=volume_gsm_dep_no_bz_cluster_15)           # ğŸ§® Dep No BZ Cluster 15 - Volume

# ğŸš€ Throughput: GSM SZ Center Region & Dep No BZ Cluster 15 (Slide 18)
update_chart(prs=prs_phase3, slide_index=18, shape_index=3, dataframe=throughput_gsm_sz_center_region_phase_03)  # ğŸš€ Center Region - Throughput
update_chart(prs=prs_phase3, slide_index=18, shape_index=2, dataframe=throughput_gsm_dep_no_bz_cluster_15)       # ğŸš€ Dep No BZ Cluster 15 - Throughput

# ğŸ“ Voice: GSM SZ Center Region & Dep No BZ Cluster 15 (Slide 19)
update_chart(prs=prs_phase3, slide_index=19, shape_index=3, dataframe=voice_gsm_sz_center_region_phase_03)       # ğŸ“ Center Region - Voice
update_chart(prs=prs_phase3, slide_index=19, shape_index=2, dataframe=voice_gsm_dep_no_bz_cluster_15)            # ğŸ“ Dep No BZ Cluster 15 - Voice
```

### 35.2 Phase-4 PPT Charts Update


```python
# ğŸ“ˆ North - Phase-4 Charts

# ğŸ“Š Data:
update_chart(prs=prs_phase4, slide_index=2, shape_index=1, dataframe=data_sunset_north_b3_sz)    
update_chart(prs=prs_phase4, slide_index=2, shape_index=0, dataframe=data_sunset_n_peshawar_sz)     
# ğŸ“¦ Volume:
update_chart(prs=prs_phase4, slide_index=3, shape_index=4, dataframe=volume_sunset_north_b3_sz)  
update_chart(prs=prs_phase4, slide_index=3, shape_index=3, dataframe=volume_sunset_n_peshawar_sz)   

# ğŸš€ Throughput: 
update_chart(prs=prs_phase4, slide_index=4, shape_index=3, dataframe=throughput_sunset_north_b3_sz)  
update_chart(prs=prs_phase4, slide_index=4, shape_index=2, dataframe=throughput_sunset_n_peshawar_sz)   

# ğŸ“ Voice: 
update_chart(prs=prs_phase4, slide_index=5, shape_index=3, dataframe=voice_sunset_north_b3_sz)       
update_chart(prs=prs_phase4, slide_index=5, shape_index=2, dataframe=voice_sunset_n_peshawar_sz)        
```


```python
# ğŸ“ˆ Center - Phase-4 Charts

# ğŸ“Š Data: 
update_chart(prs=prs_phase4, slide_index=7, shape_index=1, dataframe=data_sz_dep_cluster_9)    
update_chart(prs=prs_phase4, slide_index=7, shape_index=0, dataframe=data_sunset_sialkot)     

# ğŸ“¦ Volume:
update_chart(prs=prs_phase4, slide_index=8, shape_index=4, dataframe=volume_sz_dep_cluster_9)  
update_chart(prs=prs_phase4, slide_index=8, shape_index=3, dataframe=volume_sunset_sialkot)   

# ğŸš€ Throughput: 
update_chart(prs=prs_phase4, slide_index=9, shape_index=3, dataframe=throughput_sz_dep_cluster_9)  
update_chart(prs=prs_phase4, slide_index=9, shape_index=2, dataframe=throughput_sunset_sialkot)  

# ğŸ“ Voice: 
update_chart(prs=prs_phase4, slide_index=10, shape_index=3, dataframe=voice_sz_dep_cluster_9)      
update_chart(prs=prs_phase4, slide_index=10, shape_index=2, dataframe=voice_sunset_sialkot)        
```


```python
# ğŸ“ˆ South - Phase-4 Charts

# ğŸ“Š Data: 
update_chart(prs=prs_phase4, slide_index=12, shape_index=1, dataframe=data_south_july25_2g_p4_sz)    
update_chart(prs=prs_phase4, slide_index=12, shape_index=0, dataframe=data_south_july25_2g_lark_city)     

# ğŸ“¦ Volume:
update_chart(prs=prs_phase4, slide_index=13, shape_index=4, dataframe=volume_south_july25_2g_p4_sz)  
update_chart(prs=prs_phase4, slide_index=13, shape_index=3, dataframe=volume_south_july25_2g_lark_city)   

# ğŸš€ Throughput: 
update_chart(prs=prs_phase4, slide_index=14, shape_index=3, dataframe=throughput_south_july25_2g_p4_sz)  
update_chart(prs=prs_phase4, slide_index=14, shape_index=2, dataframe=throughput_south_july25_2g_lark_city)  

# ğŸ“ Voice: 
update_chart(prs=prs_phase4, slide_index=15, shape_index=0, dataframe=voice_south_july25_2g_p4_sz)      
update_chart(prs=prs_phase4, slide_index=15, shape_index=3, dataframe=voice_south_july25_2g_lark_city)       
```

## ğŸ” 36. Reusing User-Defined Function to Update Tables

### 36.1 Phase-3 PPT Table Update


```python
# ğŸ“‹ North - Phase-3 Table Updates

# ğŸ§® Share Table: Sunset NORTH B2 SZ
update_table_cells(prs=prs_phase3, slide_index=4, table_index=0, 
    updates=[
        (0, 1, f"{share_2G_Sunset_NORTH_B2_SZ.iloc[0, 2]}"),  # ğŸ“Œ L1800%
        (1, 1, f"{share_2G_Sunset_NORTH_B2_SZ.iloc[0, 3]}"),  # ğŸ“Œ L2100%
        (2, 1, f"{share_2G_Sunset_NORTH_B2_SZ.iloc[0, 4]}")   # ğŸ“Œ L900%
    ], 
    force_formatting=True
)

# ğŸ§® Share Table: BANNU SZ 
update_table_cells(prs=prs_phase3, slide_index=4, table_index=1, 
    updates=[
        (0, 1, f"{share_2G_Sunset_N_BANNU_SZ.iloc[0, 2]}"),   # ğŸ“Œ L1800%
        (1, 1, f"{share_2G_Sunset_N_BANNU_SZ.iloc[0, 3]}"),   # ğŸ“Œ L2100%
        (2, 1, f"{share_2G_Sunset_N_BANNU_SZ.iloc[0, 4]}")    # ğŸ“Œ L900%
    ], 
    force_formatting=True
)

# ğŸ§® Share Table: KOHAT SZ 
update_table_cells(prs=prs_phase3, slide_index=5, table_index=0, 
    updates=[
        (0, 1, f"{share_2G_Sunset_N_KOHAT_SZ.iloc[0, 2]}"),   # ğŸ“Œ L1800%
        (1, 1, f"{share_2G_Sunset_N_KOHAT_SZ.iloc[0, 3]}"),   # ğŸ“Œ L2100%
        (2, 1, f"{share_2G_Sunset_N_KOHAT_SZ.iloc[0, 4]}")    # ğŸ“Œ L900%
    ], 
    force_formatting=True
)

# ğŸ§® Share Table: HANGU SZ 
update_table_cells(prs=prs_phase3, slide_index=5, table_index=1, 
    updates=[
        (0, 1, f"{share_2G_Sunset_N_HANGU_SZ.iloc[0, 2]}"),   # ğŸ“Œ L1800%
        (1, 1, f"{share_2G_Sunset_N_HANGU_SZ.iloc[0, 3]}"),   # ğŸ“Œ L2100%
        (2, 1, f"{share_2G_Sunset_N_HANGU_SZ.iloc[0, 4]}")    # ğŸ“Œ L900%
    ], 
    force_formatting=True
)
```


```python
# ğŸ“‹ South - Phase-3 Table Updates

# ğŸ§® Share Table: South June25 SZ 
update_table_cells(
    prs=prs_phase3, 
    slide_index=12, 
    table_index=0, 
    updates=[
        (0, 1, f"{share_L9_South_June25_SZ.iloc[0, 2]}"),   # ğŸ“Œ L1800%
        (1, 1, f"{share_L9_South_June25_SZ.iloc[0, 3]}"),   # ğŸ“Œ L2100%
        (2, 1, f"{share_L9_South_June25_SZ.iloc[0, 4]}")    # ğŸ“Œ L900%
    ], 
    force_formatting=True
)

# ğŸ§® Share Table: Dera Allahyar 
update_table_cells(
    prs=prs_phase3, 
    slide_index=12, 
    table_index=1, 
    updates=[
        (0, 1, f"{share_L9_South_June25_DeraAllAHYAR.iloc[0, 2]}"),   # ğŸ“Œ L1800%
        (1, 1, f"{share_L9_South_June25_DeraAllAHYAR.iloc[0, 3]}"),   # ğŸ“Œ L2100%
        (2, 1, f"{share_L9_South_June25_DeraAllAHYAR.iloc[0, 4]}")    # ğŸ“Œ L900%
    ], 
    force_formatting=True
)
```


```python
# ğŸ“‹ Center - Phase-3 Table Updates

# ğŸ§®  GSM SZ Center Region Phase-03 
update_table_cells(
    prs=prs_phase3, 
    slide_index=17, 
    table_index=0, 
    updates=[
        (0, 1, f"{share_GSM_SZ_Center_Region_Phase_03.iloc[0, 2]}"),  # ğŸ“Œ L1800%
        (1, 1, f"{share_GSM_SZ_Center_Region_Phase_03.iloc[0, 3]}"),  # ğŸ“Œ L2100%
        (2, 1, f"{share_GSM_SZ_Center_Region_Phase_03.iloc[0, 4]}")   # ğŸ“Œ L900%
    ],
    force_formatting=True
)

# ğŸ§® Share Table: GSM Dep No BZ Cluster 15 
update_table_cells(
    prs=prs_phase3, 
    slide_index=17, 
    table_index=1, 
    updates=[
        (0, 1, f"{share_GSM_Dep_No_BZ_Cluster_15.iloc[0, 2]}"),       # ğŸ“Œ L1800%
        (1, 1, f"{share_GSM_Dep_No_BZ_Cluster_15.iloc[0, 3]}"),       # ğŸ“Œ L2100%
        (2, 1, f"{share_GSM_Dep_No_BZ_Cluster_15.iloc[0, 4]}")        # ğŸ“Œ L900%
    ],
    force_formatting=True
)
```

### 36.2 Phase-4 PPT Table Update


```python
# ğŸ“‹ North - Phase-4 Table Updates

# ğŸ§® Share Table: North Service Zone
update_table_cells(prs=prs_phase4, slide_index=3, table_index=0, 
    updates=[
        (0, 1, f"{share_Sunset_NORTH_B3_SZ.iloc[0, 2]}"),  # ğŸ“Œ L1800%
        (1, 1, f"{share_Sunset_NORTH_B3_SZ.iloc[0, 3]}"),  # ğŸ“Œ L2100%
        (2, 1, f"{share_Sunset_NORTH_B3_SZ.iloc[0, 4]}")   # ğŸ“Œ L900%
    ], 
    force_formatting=True
)

# ğŸ§® Share Table: Peshawar
update_table_cells(prs=prs_phase4, slide_index=3, table_index=1, 
    updates=[
        (0, 1, f"{share_Sunset_N_PESHAWAR_SZ.iloc[0, 2]}"),   # ğŸ“Œ L1800%
        (1, 1, f"{share_Sunset_N_PESHAWAR_SZ.iloc[0, 3]}"),   # ğŸ“Œ L2100%
        (2, 1, f"{share_Sunset_N_PESHAWAR_SZ.iloc[0, 4]}")    # ğŸ“Œ L900%
    ], 
    force_formatting=True
)
```


```python
# ğŸ“‹ Center - Phase-4 Table Updates

# ğŸ§® Share Table: Center Service Zone
update_table_cells(prs=prs_phase4, slide_index=8, table_index=0, 
    updates=[
        (0, 1, f"{share_SZ_Dep_Cluster_9.iloc[0, 2]}"),  # ğŸ“Œ L1800%
        (1, 1, f"{share_SZ_Dep_Cluster_9.iloc[0, 3]}"),  # ğŸ“Œ L2100%
        (2, 1, f"{share_SZ_Dep_Cluster_9.iloc[0, 4]}")   # ğŸ“Œ L900%
    ], 
    force_formatting=True
)

# ğŸ§® Share Table: Sialkot
update_table_cells(prs=prs_phase4, slide_index=8, table_index=1, 
    updates=[
        (0, 1, f"{share_Sunset_SIALKOT.iloc[0, 2]}"),   # ğŸ“Œ L1800%
        (1, 1, f"{share_Sunset_SIALKOT.iloc[0, 3]}"),   # ğŸ“Œ L2100%
        (2, 1, f"{share_Sunset_SIALKOT.iloc[0, 4]}")    # ğŸ“Œ L900%
    ], 
    force_formatting=True
)

```


```python
# ğŸ“‹ South - Phase-4 Table Updates

# ğŸ§® Share Table: Center Service Zone
update_table_cells(prs=prs_phase4, slide_index=13, table_index=0, 
    updates=[
        (0, 1, f"{share_South_July25_2G_P4_SZ.iloc[0, 2]}"),  # ğŸ“Œ L1800%
        (1, 1, f"{share_South_July25_2G_P4_SZ.iloc[0, 3]}"),  # ğŸ“Œ L2100%
        (2, 1, f"{share_South_July25_2G_P4_SZ.iloc[0, 4]}")   # ğŸ“Œ L900%
    ], 
    force_formatting=True
)

# ğŸ§® Share Table: Peshawar
update_table_cells(prs=prs_phase4, slide_index=13, table_index=1, 
    updates=[
        (0, 1, f"{share_South_July25_2G_Lark_city.iloc[0, 2]}"),   # ğŸ“Œ L1800%
        (1, 1, f"{share_South_July25_2G_Lark_city.iloc[0, 3]}"),   # ğŸ“Œ L2100%
        (2, 1, f"{share_South_July25_2G_Lark_city.iloc[0, 4]}")    # ğŸ“Œ L900%
    ], 
    force_formatting=True
)
```

## ğŸ’¾ 36. Save Presentation


```python
prs_phase3.save('UMTS_Sunset_Phase_3.pptx')                       # ğŸ’¾ Save the updated PowerPoint presentation to file
prs_phase4.save('UMTS_Sunset_Phase_4.pptx')                       # ğŸ’¾ Save the updated PowerPoint presentation to file
```


```python
%reset -f
```

## ğŸ§¹ 37. PowerPoint Cleanup - Automated


```python
import os
import glob
import win32com.client

# Folder path and file filter
ppt_folder = r"D:\Advance_Data_Sets\PPT_Sunset_NW"
ppt_files = glob.glob(os.path.join(ppt_folder, "UMTS_Sunset*.pptx"))

# Launch PowerPoint
ppt = win32com.client.Dispatch("PowerPoint.Application")
# Do not set ppt.Visible = False

for ppt_path in ppt_files:
    print(f"Processing: {ppt_path}")
    try:
        presentation = ppt.Presentations.Open(ppt_path, WithWindow=False)

        for slide in presentation.Slides:
            for shape in slide.Shapes:
                if shape.HasChart:
                    try:
                        chart = shape.Chart
                        workbook = chart.ChartData.Workbook
                        sheet = workbook.Worksheets(1)
                        used_range = sheet.UsedRange

                        for row in range(1, used_range.Rows.Count + 1):
                            for col in range(1, used_range.Columns.Count + 1):
                                value = sheet.Cells(row, col).Value
                                if value == 0:
                                    sheet.Cells(row, col).Value = None  # or "=NA()"

                    except Exception as chart_err:
                        print(f"  Chart error on Slide {slide.SlideIndex}: {chart_err}")

        presentation.Save()
        presentation.Close()

    except Exception as file_err:
        print(f"  Error opening {ppt_path}: {file_err}")

# Gracefully quit PowerPoint
try:
    if ppt:
        ppt.Quit()
except Exception as quit_err:
    print(f"âš ï¸ Could not quit PowerPoint: {quit_err}")

print("âœ… All matching PowerPoint files processed.")
```

    Processing: D:\Advance_Data_Sets\PPT_Sunset_NW\UMTS_Sunset_Phase_3.pptx
    Processing: D:\Advance_Data_Sets\PPT_Sunset_NW\UMTS_Sunset_Phase_4.pptx
    âœ… All matching PowerPoint files processed.
    


```python
%reset -f
```

import os                      # ğŸ“ For interacting with the operating system (file paths, directory checks, etc.)
import zipfile                 # ğŸ—œï¸ For handling ZIP archive files
import numpy as np             # ğŸ”¢ For numerical operations and arrays
import pandas as pd            # ğŸ¼ For data manipulation and analysis
from pathlib import Path       # ğŸ›¤ï¸ For object-oriented file path handling
from datetime import time      # â° For working with time objects (e.g., filtering by hour)
from functools import reduce   # ğŸ”„ For function-based reduction (e.g., combining multiple DataFrames)
from pandas import Timestamp   # ğŸ“… For handling timestamps specifically in pandas

from pptx.util import Inches                   # ğŸ“ For specifying size/dimensions of shapes or images in inches
from pptx import Presentation                  # ğŸ“Š For creating and editing PowerPoint presentations
from pptx.util import Pt                       # ğŸ”  For setting font size in points
from pptx.enum.shapes import MSO_SHAPE_TYPE    # ğŸ§© For identifying and handling different shape types in slides
from pptx.dml.color import RGBColor            # ğŸ¨ For setting custom RGB colors for text/shapes
from pptx.enum.text import PP_ALIGN            # ğŸ“ For setting paragraph alignment (left, center, right, etc.)
from pptx.chart.data import CategoryChartData  # ğŸ“ˆ For providing data to category charts (like bar/column charts)

path = 'D:/Advance_Data_Sets/PPT_Sunset_NW'                    # ğŸ“ Set working directory path for data and templates
os.chdir(path)                                                 # ğŸ”„ Change current working directory to the specified path

prs_phase4 = Presentation('template_phase3.pptx')              # ğŸ“Š Load PowerPoint template for Phase-4

# Choose the slide number (e.g., second slide)
slide = prs_phase4 .slides[19]  # 0-based index

# Loop through and print info about each shape
for idx, shape in enumerate(slide.shapes):
    shape_type = shape.shape_type
    name = getattr(shape, "name", "No name")
    print(f"Index: {idx}, Type: {shape_type}, Name: {name}, Has Chart: {shape.has_chart}")
